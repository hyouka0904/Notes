# 1 Introduction

* 統計模型在現代社會中變得無處不在且越來越重要
* 各種類型的預測已融入我們的日常生活：
  - 醫生依據模型識別特定患者群體的風險
  - 航班到達時間的數值預測
  - 律師使用統計模型量化潛在招聘偏見的可能性

## 模型的本質與目的 (Nature and Purpose of Models)

* 模型通過現有數據尋找可接受精確度的數學表示
* 模型用途分為兩類：
  - **推論型**（Inferential）：為了理解自然狀態而得出結論
    * 例如：招聘偏見的估計與「統計顯著性」的判定
  - **預測型**（Estimation）：專注於對特定值的準確預測
    * 例如：航班到達時間的預測

## 模型的重要特性 (Important Model Characteristics)

* **簡約性**（Parsimony/Simplicity）是關鍵考量
  - 簡單模型在推論目的時特別受青睞
  - 簡約性提高模型的可解釋性
  - 例如：教育年限與薪資的線性關係模型易於解釋

* **準確性**（Accuracy）不應為簡約性嚴重犧牲
  - 模型必須保持對數據的可接受忠實度
  - 複雜性通常是解決準確性差的方案
  - 使用額外參數或非線性模型可能提高準確性但降低可解釋性

* 準確性與簡約性之間的權衡是模型建構的關鍵考量

## 預測變數的重要性 (Importance of Predictors)

* 進入模型的變數及其表示方式與模型本身同樣關鍵
* 相關術語：
  - 被建模或預測的量：**結果變數**（Outcome）、**反應變數**（Response）或**因變數**（Dependent Variable）
  - 用於建模的變數：**預測變數**（Predictors）、**特徵**（Features）或**自變數**（Independent Variables）

* 特徵表示的多樣性（以房屋銷售價格為例）：
  - **位置資訊**可以多種方式表示：
    * 鄰里（Neighborhood）
    * 經緯度（Longitude/Latitude）
    * 郵遞區號（ZIP Code）作為學區的代理
  - 從資訊理論角度，經緯度提供最具體的物理位置信息

## 特徵工程 (Feature Engineering)

* **特徵工程**：創建數據表示以提高模型有效性的過程
* 模型有效性受多種因素影響：
  - 如果預測變數與結果沒有關係，其表示方式無關緊要
  - 不同模型有不同的敏感度和需求

## 不同模型對預測變數的要求 (Model Requirements for Predictors)

* 某些模型無法容忍測量相同基本量的預測變數（**多重共線性**或預測變數間相關性）
* 許多模型無法使用具有任何缺失值的樣本
* 某些模型在存在不相關預測變數時性能嚴重下降

## 本書目標 (Book Objective)

* 幫助實踐者通過專注於預測變數來建立更好的模型
* 「更好」取決於問題背景，但可能包括：準確性、簡單性和穩健性
* 理解預測變數與模型類型之間的相互作用至關重要
* 通過更適合模型的數據表示或減少使用的變數來提高準確性和/或簡化模型
## 1.1 簡單的案例分析 (A Simple Example)

* 本案例來自 Hill et al. (2007) 的實驗，展示**特徵工程**（Feature Engineering）如何影響模型效能
* 使用兩個相關的預測變數（標記為 A 和 B）
* 資料點依據其結果分為兩類：「PS」和「WS」
* 圖 1.2a 顯示兩個類別沿對角線有明確的分隔

### 邏輯迴歸模型實施 (Logistic Regression Implementation)

* 使用**邏輯迴歸模型**（Logistic Regression Model）建立預測方程式：
  $$\log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1A + \beta_2B$$
  - $p$ 是樣本屬於「PS」類別的機率
  - $\beta$ 值是需要從資料中估計的模型參數

* 資料分割與參數估計：
  - 訓練集：1009 個資料點用於估計參數
  - 測試集：1010 個樣本用於評估性能
  - 使用**最大概似估計**（Maximum Likelihood Estimation）估計參數
  - 得到的參數值：$\hat{\beta}_0 = 1.73$, $\hat{\beta}_1 = 0.003$, $\hat{\beta}_2 = -0.064$

### 模型評估方法 (Model Evaluation)

* 使用**接收者操作特徵曲線**（Receiver Operating Characteristic, ROC）評估模型
  - 避免使用固定的機率閾值（如50%）進行硬性分類
  - ROC 曲線繪製真陽性率與假陽性率的關係
  - 理想的曲線應盡可能靠近左上角
  - 無效模型的曲線會沿著對角虛線

* 使用**曲線下面積**（Area Under the ROC Curve）作為性能摘要
  - AUC = 1.0 代表完美模型
  - AUC ≈ 0.5 表示模型無預測能力
  - 原始邏輯迴歸模型的 AUC = 0.794（中等準確度）
  - 圖 1.2b 展示了原始模型的 ROC 曲線

### 預測變數轉換的影響 (Impact of Predictor Transformation)

* 由於兩個預測變數均大於零且呈右偏分布，可嘗試不同轉換：
  - 使用比率 A/B 作為單一預測因子
  - 對每個預測因子進行簡單轉換

* 利用**Box-Cox轉換**（Box-Cox Transformation）調整預測變數尺度：
  - 轉換方法建議兩個預測因子都使用倒數尺度（如 1/A 代替 A）
  - 轉換後的資料分布如圖 1.3a 所示
  - 視覺上能更清楚區分兩組資料

* 轉換後的變數帶來顯著改善：
  - AUC 從 0.794 提升到 0.848
  - 圖 1.3b 顯示，轉換後的 ROC 曲線全面優於原始結果

### 模型比較與結論 (Model Comparison and Conclusions)

* 同樣數據使用**神經網路**（Neural Network）模型：
  - 不需要進行倒數轉換也能達到 AUC = 0.848
  - 神經網路不易受預測因子分布特性的影響

* 模型選擇考量：
  - 神經網路：完全不可解釋，需要大量參數調整
  - 依據**沒有免費午餐定理**（No Free Lunch Theorem），不應武斷地認為某模型永遠優於另一個
  - 根據模型用途（推論分析 vs. 純預測），選擇適當的模型

* 案例關鍵啟示：
  - 簡單的特徵轉換可以顯著提高模型效能
  - 不同模型對數據特性有不同的敏感度
  - 適合的特徵工程可以簡化模型或提高其性能

## 1.2 重要概念 (Important Concepts)

### 過擬合 (Overfitting)
* 指模型在當前數據上表現良好，但在新樣本上預測失敗的情況
* 典型原因：模型過度依賴當前數據集中的特定模式和趨勢
* 例如：預測房價時，發現「面積在1,267.5至1,277平方呎且有三間臥室的房屋」價格可準確預測，但此模式不具泛化性
* 高彈性（低偏差）模型更容易過擬合
* 變數選擇也可能過擬合，特別是當樣本數（n）小而預測變數數量（p）大時

### 監督式與非監督式程序 (Supervised and Unsupervised Procedures)
* **監督式分析**（Supervised Analysis）：識別預測變數與目標結果之間的模式
* **非監督式分析**（Unsupervised Analysis）：專注於預測變數之間的模式
* 兩種方法通常都使用**探索性數據分析**（Exploratory Data Analysis, EDA）
* 監督式分析更容易發現數據中的錯誤模式
* 需避免「自我實現的預測預言」：使用同一數據進行變數選擇和視覺化會產生「挑揀結果」現象

### 沒有免費午餐定理 (No Free Lunch)
* 在沒有特定問題或數據知識的情況下，沒有單一預測模型是最佳的
* 不同模型針對不同數據特性（如缺失值或共線性預測因子）進行優化
* 研究顯示某些模型平均表現較佳，但勝率不足以支持「總是使用模型X」的策略
* 實務建議：嘗試多種不同類型的模型來確定哪一種最適合特定數據集

### 模型與建模過程 (The Model versus the Modeling Process)
* 發展有效模型的過程是迭代性和啟發式的
* 圖1.4展示典型建模過程：
  * (a) 探索性數據分析（EDA）
  * (b) 初步數據分析
  * (c) 預測因子表達的第一稿
  * (d) 模型調優（超參數調整）
  * (e) 模型評估
  * (f) 對模型結果進行EDA
  * (g) 再一輪特徵工程
  * (h) 更廣泛的模型調優
  * (i) 最終模型評估
  * (j) 最終模型選擇
* 建模過程不僅僅是擬合單一數學模型，還包含多個反饋循環

### 模型偏差與變異 (Model Bias and Variance)
* **變異**（Variance）：模型參數因數據微小變化而改變的程度
  * 低變異模型：線性迴歸、邏輯迴歸、偏最小平方法
  * 高變異模型：決策樹、最近鄰模型、神經網路
* **偏差**（Bias）：模型符合數據基本結構的能力
  * 高偏差模型：線性方法（無法描述非線性模式）
  * 低偏差模型：決策樹、支持向量機、神經網路
* 變異-偏差權衡：低偏差模型傾向於高變異，反之亦然
* 圖1.5展示非線性數據集被兩種方法擬合：
  * 三點移動平均（綠色）：高變異但能較好跟蹤數據趨勢
  * 二次迴歸（紫色）：低變異但不能準確擬合非線性趨勢
* 圖1.6顯示這兩種模型在加入隨機噪聲後的表現：
  * 移動平均：預測有噪聲但平均而言能跟蹤數據模式
  * 二次模型：不受額外噪聲干擾但生成相似（且不準確）的擬合

### 經驗驅動與數據驅動建模 (Experience-Driven and Empirically Driven Modeling)
* **經驗驅動建模**：利用主題專家知識確定變數及其表示方式
* **數據驅動建模**：讓數據決定哪些預測因子及表示方法應被使用
* 數據驅動方法的風險：
  * 過擬合到數據中的虛假模式
  * 可能產生高度複雜且沒有明顯合理解釋的模型
* 最佳方法：結合兩種方法
  * 專家對新特徵更有信心，前提是發現方法嚴謹
  * 數據分析師從專家建議中受益，尤其是在初步篩選或優先順序預測因子時

### 大數據 (Big Data)
* 有效樣本量可能小於實際數據量（例如，嚴重類別不平衡或稀有事件率）
* 大數據的潛在缺點：
  * 如果預測因子與結果間無關係，增加數據量無法解決問題
  * 對複雜模型產生計算挑戰，計算時間可能隨數據量非線性增加
  * 並非所有模型都能從大數據中獲益（如高偏差、低變異模型）
* 可有效利用大數據的模型包括利用未標記數據的模型
* 面對大數據的關鍵問題：
  * 你用它來做什麼？它是否解決了某個未滿足的需求？
  * 它會造成障礙嗎？

  ## 1.2 更複雜的案例 (A More Complex Example)

* 本案例研究預測芝加哥「L」列車的乘客量（特定車站每日進站人數）
* 目的：幫助芝加哥交通管理局適當配置列車和車廂數量

### 案例分析過程 (Analysis Process)

* **初始預測變數集（Set 1）**：
  - 簡單易計算的四個預測因子
  - 與乘客量有強關聯性（通過視覺化確認）
  - 使用**均方根誤差**（Root Mean Squared Error, RMSE）評估模型
  - RMSE值範圍在2331至3248人次/日
  - 樹狀模型表現最佳，線性模型表現最差
  - 同類型模型間RMSE變異很小

* **第二組預測變數（Set 2）**：
  - 增加128個數值型預測變數（不同車站乘客量的滯後版本）
  - 例如：使用今天的乘客量預測一週後的乘客量（七天滯後）
  - 整體效果良好，對線性模型特別有幫助
  - 不同模型和模型類型獲益程度不同

* **第三組預測變數（Set 3）**：
  - 新增8至14天的滯後變數
  - 許多變數與其他預測因子有強相關性
  - 與前一組模型相比，沒有明顯改善，某些甚至更差
  - 某些線性模型因變數間高度相關（**多重共線性**，Multicollinearity）而表現下降
  - 此組滯後變數未顯示總體收益，未進一步考慮

* **第四組預測變數（Set 4）**：
  - 增加18個天氣狀況相關預測因子
  - 與第一、第二組一起使用
  - 天氣變數對預測列車乘客量沒有相關性

* **第五組預測變數（Set 5）**：
  - 開發49個二元預測變數，針對當前最佳模型表現不佳的日子
  - 基於殘差圖的探索性數據分析結果
  - 模型誤差大幅下降
  - 使用第一、第二和第五組特徵集，簡單線性模型的結果與更複雜的模型技術相當

### 關鍵結論 (Key Takeaways)

1. 建模過程幾乎不可能通過單一模型或特徵集立即解決問題，更像是一場反覆試錯的**戰役**（Campaign）
2. 特徵集的影響**可能**遠大於不同模型的影響
3. 模型與特徵之間的相互作用複雜且難以預測
4. 使用正確的預測變數集，多種不同類型的模型可達到相同性能水平
   - 初期表現最差的線性模型，最終展現了最佳性能

## 1.4 特徵選擇 (Feature Selection)

* 前例中，新特徵集被依序衍生以改善模型性能
  - 開發特徵集、加入模型，再用**重抽樣**（Resampling）評估其效用
  - 新預測變數事先未經篩選統計顯著性，這屬於**監督式程序**（Supervised Procedure）
  - 需注意避免過擬合

### 特徵選擇的必要性 (The Necessity of Feature Selection)

* 前例特徵集（如集合1、2和5）能充分預測結果，但可能包含：
  - 非資訊性變數（影響性能）
  - 重要變數被埋沒在集合3和4的非資訊性變數中

* 特徵選擇方法應用場景：
  - **連續法**：當新預測變數逐步加入模型時
  - **非連續法**：所有原始預測變數在建模過程開始時即已知且可用

### 監督式特徵選擇策略 (Supervised Feature Selection Strategies)

* 根據子集衍生方式區分搜尋方法：

* **包裹方法**（Wrapper Methods）
  - 使用外部搜尋程序選擇不同的預測變數子集進行評估
  - 特徵搜尋過程與模型擬合過程分離
  - 例子：向後或逐步選擇、**基因演算法**（Genetic Algorithms）

* **嵌入方法**（Embedded Methods）
  - 特徵選擇程序自然發生於模型擬合過程中
  - 例子：簡單**決策樹**（Decision Tree）
  - 變數在模型用於分割時被選擇
  - 如果預測變數從未用於分割，預測方程與該變數無關，則被排除

* 主要風險：過擬合
  - 使用包裹方法時尤其如此
  - 當訓練集數據點數量相對於預測變數數量較小時風險增加

### 非監督式選擇方法 (Unsupervised Selection Methods)

* 非監督式選擇方法可對模型性能產生積極影響
* 例如Ames住房數據的鄰里變數：
  - 鄰里變數有28個可能值，轉換為27個二元變數
  - 其中2個鄰里只有一或兩個屬性，占總體不到1%
  - 這種低頻率預測變數可能對某些模型（如線性迴歸）產生有害影響
  - 建議在建模前移除這些變數

### 變數子集搜尋的考量 (Considerations for Variable Subset Search)

* 可能不存在唯一的最佳性能預測變數集
* 存在補償效應：
  - 移除某個看似重要的變數時，模型使用剩餘變數進行調整
  - 在解釋變數之間存在相關性或使用低偏差模型時尤其明顯

* 特徵選擇不應作為確定特徵顯著性的正式方法
* 對評估預測變數對基礎模型或數據集的貢獻：
  - 建議使用更傳統的推論統計方法

  ## 1.5 本書大綱 (An Outline of the Book)

* 本書目標：提供有效工具來發現相關且具預測性的預測變數表達方式
* 這些工具將成為預測建模過程的兩端：
  - 過程開始：探索增強預測變數集的技術
  - 過程結束：提供篩選增強預測變數集的方法，以產生更好的模型

### 各章節內容概述 (Chapter Overview)

* **第2章**：模型與特徵工程過程互動的簡短說明
  - 使用特徵工程和特徵選擇方法改善預測缺血性中風風險的模型能力

* **第3章**：預測模型開發過程回顧
  - 資料分割、驗證方法選擇、模型調優、未來預測性能估計
  - 在多個模型的模型建構過程中使用反饋循環的指導

* **第4章**：資料探索性視覺化
  - 理解預測變數之間以及預測變數與響應變數之間關係的視覺化技術
  - 評估個別預測變數特性（偏度、缺失值模式）的視覺化方法
  - 評估模型擬合不良的圖形方法

* **第5章**：**類別型預測變數**（Categorical Predictors）編碼方法
  - 表示類別型預測變數的標準技術
  - 類別型預測變數的特徵工程方法，如**特徵雜湊**（Feature Hashing）
  - 處理類別型預測變數中罕見水平的實用問題
  - 為樹狀和規則型模型創建**虛擬變數**（Dummy Variables）的影響
  - 基於日期的預測變數處理（可視為類別型預測變數）

* **第6章**：**數值型預測變數**（Numeric Predictors）工程
  - 單變量和多變量轉換作為尋找更好形式的第一步
  - 使用**基底展開**（Basis Expansions）如樣條函數（Splines）創建更好的表示
  - 將連續預測變數轉換為類別或序數箱，以減少變異並提高性能
  - 數值預測變數分箱的注意事項

* **第7章**：**交互作用效應**（Interaction Effects）檢測
  - 探索兩個或多個原始預測變數之間交互作用的重要性
  - 確定預測變數之間交互作用的量化工具
  - 評估這些效應重要性的圖形方法
  - 交互作用可估計性的概念探討

* **第8章**：處理**缺失數據**（Missing Data）
  - 探索缺失數據的機制
  - 調查缺失數據模式的視覺化工具
  - 移除或插補缺失數據的傳統和現代工具
  - 評估連續和類別型預測變數的插補方法

* **第9章**：處理**剖面數據**（Profile Data）
  - 處理時間序列（縱向）、細胞-孔板、圖像等特殊結構數據
  - 金融、製藥、情報、交通和天氣預報領域常見的數據類型
  - 介紹**偏最小平方法**（Partial Least Squares）等自然處理此類數據的工具
  - 在建模前總結或壓縮剖面數據的技術

* **第10-12章**：**特徵選擇**（Feature Selection）策略
  - 特徵選擇的目標
  - 無關預測變數的後果
  - 與通過**正則化**（Regularization）進行選擇的比較
  - 如何避免特徵選擇過程中的過擬合

  # 2 說明性案例：預測缺血性中風風險 (Illustrative Example: Predicting Risk of Ischemic Stroke)

* 本章節作為特徵工程的入門，展示類似圖1.4所示的建模過程
* 為說明目的，本例將聚焦於探索、分析擬合和特徵工程，通過單一模型（邏輯迴歸）視角

## 研究背景與假設 (Background and Hypothesis)

* 傳統上，動脈狹窄（阻塞）程度用於識別中風風險患者
* 阻塞充分（>70%）的患者通常建議進行手術干預
* 歷史證據表明阻塞程度本身實際上是未來中風的較差預測因子
* 理論認為：同等大小的阻塞，**斑塊阻塞的組成**也與中風風險相關
  - 大型但穩定且不易破裂的斑塊可能比小型但不穩定的斑塊風險更低

## 研究數據集 (Dataset)

* 選擇了126位具有不同程度頸動脈阻塞的患者歷史數據
  - 其中44位患者阻塞大於70%
* 所有患者接受了**電腦斷層血管造影**（Computed Tomography Angiography, CTA）
* 使用Elucid Bioimaging的vascuCAP™軟件分析圖像，生成解剖結構估計：
  - 狹窄百分比
  - 動脈壁厚度
  - 組織特性（如富含脂質的壞死核心和鈣化）

## 圖像特徵與測量 (Imaging Features and Measurements)

* **圖2.1(a)**：表示嚴重狹窄的頸動脈
  - 軟件可計算面積（MaxStenosisByArea）和直徑（MaxStenosisByDiameter）的最大橫截面狹窄
  - 灰色區域代表提供動脈壁結構支持的大分子，可通過面積量化（MATXArea）

* **圖2.1(b)**：顯示嚴重狹窄和鈣化斑塊（綠色）及富含脂質的壞死核心（黃色）
  - 斑塊和富含脂質的壞死核心被認為會增加中風風險
  - 可通過體積（CALCVol和LRNCVol）和最大橫截面積（MaxCALCArea和MaxLRNCArea）量化

* **圖2.1(c)**：顯示嚴重狹窄和向外的動脈壁生長
  - 頂部箭頭表示最大狹窄的橫截面
  - 底部箭頭表示最大正壁重塑的橫截面
  - **重塑比例**（Remodeling Ratio）：測量動脈壁，比例小於1表示壁收縮，大於1表示壁生長
  - 大比例的冠狀動脈與破裂相關

## 阻塞與中風結果 (Blockage and Stroke Outcome)

* 表2.1顯示阻塞分類與中風結果的關聯
* 基於卡方關聯檢驗（p = 0.42），關聯不具統計顯著性
* 表明阻塞分類本身可能不是中風結果的良好預測因子

## 研究目標與額外數據 (Study Objectives and Additional Data)

* 如果斑塊特性對評估中風風險重要，成像軟件提供的測量可能有助於改善中風預測
* 改善預測能力可幫助醫生做出更好的患者管理或臨床干預決策：
  - 有大型（阻塞>70%）但穩定斑塊的患者可能不需要手術干預
  - 有較小但不穩定斑塊的患者可能需要手術干預或更積極的藥物治療

* 每位患者的數據還包括常見的臨床特徵：
  - 是否有心房顫動
  - 冠狀動脈疾病
  - 吸煙史
  - 性別和年齡等人口統計學資料

## 分析方法 (Analysis Approach)

* 將訓練模型使用風險預測因子、成像預測因子及兩者組合
* 探索這些特徵的其他表示方式，以提取有益的預測信息
* 首先評估容易收集的臨床風險因子（不需要昂貴的成像技術）

## 2.1 資料分割 (Splitting)

* 在建立模型前，需將數據分割為兩部分：
  - **訓練集**（Training Set）：用於開發模型、預處理預測變數和探索關係
  - **測試集**（Test Set）：作為預測變數集/模型組合性能的最終評判

* **分層**（Stratified）分割方法：
  - 在每個結果類別中進行隨機分割
  - 保持中風患者的比例大致相同（見表2.2）
  - 原始數據集的70%分配給訓練集

* **表2.2：按訓練和測試分割的中風結果分布**
  | 數據集 | 中風 = 是 (n) | 中風 = 否 (n) |
  | ------ | ------------- | ------------- |
  | 訓練集 | 51% (45)      | 49% (44)      |
  | 測試集 | 51% (19)      | 49% (18)      |

* 分層抽樣的優點：
  - 確保訓練和測試集具有相似的結果分布
  - 減少樣本偏差的風險
  - 提高最終模型評估的可靠性

  ## 2.2 預處理 (Preprocessing)

* 建模過程的首要步驟是了解預測變數的重要特性：
  - 個別分佈
  - 每個預測變數中缺失值的程度
  - 預測變數中潛在的異常值
  - 預測變數之間的關係
  - 每個預測變數與結果變數的關係

* 當預測變數數量增加時，仔細檢視每個變數的能力迅速下降
  - 自動化工具和視覺化可實施良好實踐
  - 參考 Kuhn (2008) 和 Wickham and Grolemund (2016)

### 處理缺失值 (Handling Missing Values)

* 數據集中僅有4個缺失值（所有受試者和預測變數）
* 許多模型無法容忍任何缺失值，因此必須採取行動
* 使用**中位數插補**（Median Imputation）替換缺失值：
  - 簡單、無偏的方法
  - 適用於相對少量的缺失（但非最佳方案）
  - 更多插補技術將在第8章討論

### 預測變數的探索 (Exploration of Predictors)

* 數據集夠小，可進行手動探索
* 成像預測變數的單變量探索發現許多有趣特性：
  - 預測變數進行了**均值中心化**和**單位方差縮放**以便直接視覺比較
  - 許多成像預測變數具有長尾分佈（正偏分佈）
  
* 範例：富含脂質壞死核心的最大橫截面積（MaxLRNCArea）
  - 圖2.2a 顯示原始偏斜分佈
  - 初看可能認為偏度和高度異常值是由少數患者引起
  - 但偏度通常是數據基本分佈的結果，不是異常值

* 解決方案：數據轉換
  - 簡單的**對數轉換**（Log-transformation）
  - 或更複雜的**Box-Cox**或**Yeo-Johnson轉換**（第6.1節）
  - 使數據在近似對稱的尺度上，消除異常值的外觀（圖2.2b）
  - 對於指數增長的測量特別適用
  - 脂質面積自然地乘法增長（面積計算的定義）

### 處理高相關性預測變數 (Handling Correlated Predictors)

* 移除與其他預測變數高度相關（r² > 0.9）的預測變數
* 圖2.3熱圖顯示成像預測變數之間的相關性
  - 列和行順序由聚類算法決定
  - 三對預測變數顯示不可接受的高相關性（紅色方框）：
    1. 血管壁體積（WallVol）和基質體積（MATXVol）
    2. 最大橫截面壁面積（MaxWallArea）和最大基質面積（MaxMATXArea）
    3. 基於面積的最大橫截面狹窄（MaxStenosisByArea）和基於直徑的最大橫截面狹窄（MaxStenosisByDiameter）
  
* 對最後一對高相關的理解：面積計算是直徑的函數
* 其他接近閾值的中度高相關變數對：
  - 鈣化體積（CALCVol）和最大橫截面鈣化面積（MaxCALCArea）(r = 0.87)
  - 富含脂質壞死核心的最大橫截面積（MaxLRNCArea）和富含脂質壞死核心的體積（LRNCVol）(r = 0.8)

* 相關性閾值是任意的，可能需要根據問題和使用的模型調整
  - 第3章包含更多關於此方法的詳細信息

  ## 2.3 探索 (Exploration)

* 下一步是探索潛在的預測關係：
  - 個別預測變數與結果之間的關係
  - 預測變數對之間與結果的關係

* 確保不過度解釋小數據集中的趨勢：
  - 使用**重抽樣**（Resampling）技術
  - 採用**重複10折交叉驗證**（Repeated 10-fold Cross-validation）
  - 創建訓練集的50個變種，用於評估所有分析
  - 提供防止過擬合的保護機制

### 模型比較方法論 (Model Comparison Methodology)

* 傳統方法缺點：在整個數據集上進行統計假設檢驗，可能導致過擬合
* 替代方法：比較兩個模型（M₁和M₂）的演算法（圖像1）：
  1. 對每個重抽樣樣本，使用90%擬合兩個模型
  2. 用兩個模型預測剩餘10%
  3. 計算兩個模型的ROC曲線下面積
  4. 確定兩個AUC值的差異
  5. 使用單側t檢定測試M₂是否優於M₁
  
* 90%和10%數值源於使用10折交叉驗證

### 風險預測變數分析 (Risk Predictors Analysis)

* 比較兩個邏輯迴歸模型：
  - 簡單模型（僅包含截距項）
  - 複雜模型（包含風險集中的單個預測變數）
  
* 表2.3（圖像2）顯示每個風險預測變數相對於空模型的ROC改善
* 多個預測變數提供顯著但有限的改善：
  - **冠狀動脈疾病**（CoronaryArteryDisease）：0.079改善，p=0.0003
  - **糖尿病病史**（DiabetesHistory）：0.066改善，p=0.0003
  - **高血壓病史**（HypertensionHistory）：0.065改善，p=0.0004
  - **年齡**（Age）：0.083改善，p=0.0011
  - **心房顫動**（AtrialFibrillation）：0.044改善，p=0.0013

### 成像預測變數分析 (Imaging Predictors Analysis)

* 圖2.4（圖像3）展示每個成像預測變數與中風結果的散點圖
* 與中風結果關聯最強的變數：
  - 目標所有橫截面中的最厚壁厚（MaxMaxWallThickness）
  - 最大橫截面壁重塑比率（MaxRemodelingRatio）
  
* MaxRemodelingRatio分析：
  - 中風類別間平均值有顯著差異
  - 但分布仍有相當重疊
  - 圖2.5（圖像4）顯示其ROC曲線
  - 顯示有一定信號，但可能不足以作為單獨的預後工具

### 交互作用探索 (Interaction Exploration)

* 探索預測變數之間的配對交互作用：
  - 數值預測變數的交互作用通過乘法生成
  - 從成像預測變數對中創建了171個潛在交互作用項
  
* 圖2.6（圖像5）展示：
  - x軸：交互作用項導致的ROC改善
  - y軸：改善的負對數p值（值越大越顯著）
  - 點的大小：主效應模型的基線ROC曲線下面積
  
* 171個交互作用項中，18個提供了相對於主效應的改善（p < 0.2）

* MaxRemodelingRatio與MaxStenosisByArea的交互作用：
  - 圖2.7（圖像6）面板(a)：兩個預測變數的散點圖，按中風結果著色
  - 等值線代表兩個預測變數之間的等效乘積值
  - 未發生中風的患者通常具有較低的乘積值
  - 發生中風的患者通常具有較高的乘積值
  - 實際意義：顯著阻塞結合血管壁向外生長增加中風風險
  - 面板(b)：這種交互作用的箱形圖顯示中風結果類別之間的分離比任一單獨預測變數更強

  