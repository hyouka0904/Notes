# 1 Introduction

* 統計模型在現代社會中變得無處不在且越來越重要
* 各種類型的預測已融入我們的日常生活：
  - 醫生依據模型識別特定患者群體的風險
  - 航班到達時間的數值預測
  - 律師使用統計模型量化潛在招聘偏見的可能性

## 模型的本質與目的 (Nature and Purpose of Models)

* 模型通過現有數據尋找可接受精確度的數學表示
* 模型用途分為兩類：
  - **推論型**（Inferential）：為了理解自然狀態而得出結論
    * 例如：招聘偏見的估計與「統計顯著性」的判定
  - **預測型**（Estimation）：專注於對特定值的準確預測
    * 例如：航班到達時間的預測

## 模型的重要特性 (Important Model Characteristics)

* **簡約性**（Parsimony/Simplicity）是關鍵考量
  - 簡單模型在推論目的時特別受青睞
  - 簡約性提高模型的可解釋性
  - 例如：教育年限與薪資的線性關係模型易於解釋

* **準確性**（Accuracy）不應為簡約性嚴重犧牲
  - 模型必須保持對數據的可接受忠實度
  - 複雜性通常是解決準確性差的方案
  - 使用額外參數或非線性模型可能提高準確性但降低可解釋性

* 準確性與簡約性之間的權衡是模型建構的關鍵考量

## 預測變數的重要性 (Importance of Predictors)

* 進入模型的變數及其表示方式與模型本身同樣關鍵
* 相關術語：
  - 被建模或預測的量：**結果變數**（Outcome）、**反應變數**（Response）或**因變數**（Dependent Variable）
  - 用於建模的變數：**預測變數**（Predictors）、**特徵**（Features）或**自變數**（Independent Variables）

* 特徵表示的多樣性（以房屋銷售價格為例）：
  - **位置資訊**可以多種方式表示：
    * 鄰里（Neighborhood）
    * 經緯度（Longitude/Latitude）
    * 郵遞區號（ZIP Code）作為學區的代理
  - 從資訊理論角度，經緯度提供最具體的物理位置信息

## 特徵工程 (Feature Engineering)

* **特徵工程**：創建數據表示以提高模型有效性的過程
* 模型有效性受多種因素影響：
  - 如果預測變數與結果沒有關係，其表示方式無關緊要
  - 不同模型有不同的敏感度和需求

## 不同模型對預測變數的要求 (Model Requirements for Predictors)

* 某些模型無法容忍測量相同基本量的預測變數（**多重共線性**或預測變數間相關性）
* 許多模型無法使用具有任何缺失值的樣本
* 某些模型在存在不相關預測變數時性能嚴重下降

## 本書目標 (Book Objective)

* 幫助實踐者通過專注於預測變數來建立更好的模型
* 「更好」取決於問題背景，但可能包括：準確性、簡單性和穩健性
* 理解預測變數與模型類型之間的相互作用至關重要
* 通過更適合模型的數據表示或減少使用的變數來提高準確性和/或簡化模型
## 1.1 簡單的案例分析 (A Simple Example)

* 本案例來自 Hill et al. (2007) 的實驗，展示**特徵工程**（Feature Engineering）如何影響模型效能
* 使用兩個相關的預測變數（標記為 A 和 B）
* 資料點依據其結果分為兩類：「PS」和「WS」
* 圖 1.2a 顯示兩個類別沿對角線有明確的分隔

### 邏輯迴歸模型實施 (Logistic Regression Implementation)

* 使用**邏輯迴歸模型**（Logistic Regression Model）建立預測方程式：
  $$\log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1A + \beta_2B$$
  - $p$ 是樣本屬於「PS」類別的機率
  - $\beta$ 值是需要從資料中估計的模型參數

* 資料分割與參數估計：
  - 訓練集：1009 個資料點用於估計參數
  - 測試集：1010 個樣本用於評估性能
  - 使用**最大概似估計**（Maximum Likelihood Estimation）估計參數
  - 得到的參數值：$\hat{\beta}_0 = 1.73$, $\hat{\beta}_1 = 0.003$, $\hat{\beta}_2 = -0.064$

### 模型評估方法 (Model Evaluation)

* 使用**接收者操作特徵曲線**（Receiver Operating Characteristic, ROC）評估模型
  - 避免使用固定的機率閾值（如50%）進行硬性分類
  - ROC 曲線繪製真陽性率與假陽性率的關係
  - 理想的曲線應盡可能靠近左上角
  - 無效模型的曲線會沿著對角虛線

* 使用**曲線下面積**（Area Under the ROC Curve）作為性能摘要
  - AUC = 1.0 代表完美模型
  - AUC ≈ 0.5 表示模型無預測能力
  - 原始邏輯迴歸模型的 AUC = 0.794（中等準確度）
  - 圖 1.2b 展示了原始模型的 ROC 曲線

### 預測變數轉換的影響 (Impact of Predictor Transformation)

* 由於兩個預測變數均大於零且呈右偏分布，可嘗試不同轉換：
  - 使用比率 A/B 作為單一預測因子
  - 對每個預測因子進行簡單轉換

* 利用**Box-Cox轉換**（Box-Cox Transformation）調整預測變數尺度：
  - 轉換方法建議兩個預測因子都使用倒數尺度（如 1/A 代替 A）
  - 轉換後的資料分布如圖 1.3a 所示
  - 視覺上能更清楚區分兩組資料

* 轉換後的變數帶來顯著改善：
  - AUC 從 0.794 提升到 0.848
  - 圖 1.3b 顯示，轉換後的 ROC 曲線全面優於原始結果

### 模型比較與結論 (Model Comparison and Conclusions)

* 同樣數據使用**神經網路**（Neural Network）模型：
  - 不需要進行倒數轉換也能達到 AUC = 0.848
  - 神經網路不易受預測因子分布特性的影響

* 模型選擇考量：
  - 神經網路：完全不可解釋，需要大量參數調整
  - 依據**沒有免費午餐定理**（No Free Lunch Theorem），不應武斷地認為某模型永遠優於另一個
  - 根據模型用途（推論分析 vs. 純預測），選擇適當的模型

* 案例關鍵啟示：
  - 簡單的特徵轉換可以顯著提高模型效能
  - 不同模型對數據特性有不同的敏感度
  - 適合的特徵工程可以簡化模型或提高其性能

## 1.2 重要概念 (Important Concepts)

### 過擬合 (Overfitting)
* 指模型在當前數據上表現良好，但在新樣本上預測失敗的情況
* 典型原因：模型過度依賴當前數據集中的特定模式和趨勢
* 例如：預測房價時，發現「面積在1,267.5至1,277平方呎且有三間臥室的房屋」價格可準確預測，但此模式不具泛化性
* 高彈性（低偏差）模型更容易過擬合
* 變數選擇也可能過擬合，特別是當樣本數（n）小而預測變數數量（p）大時

### 監督式與非監督式程序 (Supervised and Unsupervised Procedures)
* **監督式分析**（Supervised Analysis）：識別預測變數與目標結果之間的模式
* **非監督式分析**（Unsupervised Analysis）：專注於預測變數之間的模式
* 兩種方法通常都使用**探索性數據分析**（Exploratory Data Analysis, EDA）
* 監督式分析更容易發現數據中的錯誤模式
* 需避免「自我實現的預測預言」：使用同一數據進行變數選擇和視覺化會產生「挑揀結果」現象

### 沒有免費午餐定理 (No Free Lunch)
* 在沒有特定問題或數據知識的情況下，沒有單一預測模型是最佳的
* 不同模型針對不同數據特性（如缺失值或共線性預測因子）進行優化
* 研究顯示某些模型平均表現較佳，但勝率不足以支持「總是使用模型X」的策略
* 實務建議：嘗試多種不同類型的模型來確定哪一種最適合特定數據集

### 模型與建模過程 (The Model versus the Modeling Process)
* 發展有效模型的過程是迭代性和啟發式的
* 圖1.4展示典型建模過程：
  * (a) 探索性數據分析（EDA）
  * (b) 初步數據分析
  * (c) 預測因子表達的第一稿
  * (d) 模型調優（超參數調整）
  * (e) 模型評估
  * (f) 對模型結果進行EDA
  * (g) 再一輪特徵工程
  * (h) 更廣泛的模型調優
  * (i) 最終模型評估
  * (j) 最終模型選擇
* 建模過程不僅僅是擬合單一數學模型，還包含多個反饋循環

### 模型偏差與變異 (Model Bias and Variance)
* **變異**（Variance）：模型參數因數據微小變化而改變的程度
  * 低變異模型：線性迴歸、邏輯迴歸、偏最小平方法
  * 高變異模型：決策樹、最近鄰模型、神經網路
* **偏差**（Bias）：模型符合數據基本結構的能力
  * 高偏差模型：線性方法（無法描述非線性模式）
  * 低偏差模型：決策樹、支持向量機、神經網路
* 變異-偏差權衡：低偏差模型傾向於高變異，反之亦然
* 圖1.5展示非線性數據集被兩種方法擬合：
  * 三點移動平均（綠色）：高變異但能較好跟蹤數據趨勢
  * 二次迴歸（紫色）：低變異但不能準確擬合非線性趨勢
* 圖1.6顯示這兩種模型在加入隨機噪聲後的表現：
  * 移動平均：預測有噪聲但平均而言能跟蹤數據模式
  * 二次模型：不受額外噪聲干擾但生成相似（且不準確）的擬合

### 經驗驅動與數據驅動建模 (Experience-Driven and Empirically Driven Modeling)
* **經驗驅動建模**：利用主題專家知識確定變數及其表示方式
* **數據驅動建模**：讓數據決定哪些預測因子及表示方法應被使用
* 數據驅動方法的風險：
  * 過擬合到數據中的虛假模式
  * 可能產生高度複雜且沒有明顯合理解釋的模型
* 最佳方法：結合兩種方法
  * 專家對新特徵更有信心，前提是發現方法嚴謹
  * 數據分析師從專家建議中受益，尤其是在初步篩選或優先順序預測因子時

### 大數據 (Big Data)
* 有效樣本量可能小於實際數據量（例如，嚴重類別不平衡或稀有事件率）
* 大數據的潛在缺點：
  * 如果預測因子與結果間無關係，增加數據量無法解決問題
  * 對複雜模型產生計算挑戰，計算時間可能隨數據量非線性增加
  * 並非所有模型都能從大數據中獲益（如高偏差、低變異模型）
* 可有效利用大數據的模型包括利用未標記數據的模型
* 面對大數據的關鍵問題：
  * 你用它來做什麼？它是否解決了某個未滿足的需求？
  * 它會造成障礙嗎？

  ## 1.2 更複雜的案例 (A More Complex Example)

* 本案例研究預測芝加哥「L」列車的乘客量（特定車站每日進站人數）
* 目的：幫助芝加哥交通管理局適當配置列車和車廂數量

### 案例分析過程 (Analysis Process)

* **初始預測變數集（Set 1）**：
  - 簡單易計算的四個預測因子
  - 與乘客量有強關聯性（通過視覺化確認）
  - 使用**均方根誤差**（Root Mean Squared Error, RMSE）評估模型
  - RMSE值範圍在2331至3248人次/日
  - 樹狀模型表現最佳，線性模型表現最差
  - 同類型模型間RMSE變異很小

* **第二組預測變數（Set 2）**：
  - 增加128個數值型預測變數（不同車站乘客量的滯後版本）
  - 例如：使用今天的乘客量預測一週後的乘客量（七天滯後）
  - 整體效果良好，對線性模型特別有幫助
  - 不同模型和模型類型獲益程度不同

* **第三組預測變數（Set 3）**：
  - 新增8至14天的滯後變數
  - 許多變數與其他預測因子有強相關性
  - 與前一組模型相比，沒有明顯改善，某些甚至更差
  - 某些線性模型因變數間高度相關（**多重共線性**，Multicollinearity）而表現下降
  - 此組滯後變數未顯示總體收益，未進一步考慮

* **第四組預測變數（Set 4）**：
  - 增加18個天氣狀況相關預測因子
  - 與第一、第二組一起使用
  - 天氣變數對預測列車乘客量沒有相關性

* **第五組預測變數（Set 5）**：
  - 開發49個二元預測變數，針對當前最佳模型表現不佳的日子
  - 基於殘差圖的探索性數據分析結果
  - 模型誤差大幅下降
  - 使用第一、第二和第五組特徵集，簡單線性模型的結果與更複雜的模型技術相當

### 關鍵結論 (Key Takeaways)

1. 建模過程幾乎不可能通過單一模型或特徵集立即解決問題，更像是一場反覆試錯的**戰役**（Campaign）
2. 特徵集的影響**可能**遠大於不同模型的影響
3. 模型與特徵之間的相互作用複雜且難以預測
4. 使用正確的預測變數集，多種不同類型的模型可達到相同性能水平
   - 初期表現最差的線性模型，最終展現了最佳性能

## 1.4 特徵選擇 (Feature Selection)

* 前例中，新特徵集被依序衍生以改善模型性能
  - 開發特徵集、加入模型，再用**重抽樣**（Resampling）評估其效用
  - 新預測變數事先未經篩選統計顯著性，這屬於**監督式程序**（Supervised Procedure）
  - 需注意避免過擬合

### 特徵選擇的必要性 (The Necessity of Feature Selection)

* 前例特徵集（如集合1、2和5）能充分預測結果，但可能包含：
  - 非資訊性變數（影響性能）
  - 重要變數被埋沒在集合3和4的非資訊性變數中

* 特徵選擇方法應用場景：
  - **連續法**：當新預測變數逐步加入模型時
  - **非連續法**：所有原始預測變數在建模過程開始時即已知且可用

### 監督式特徵選擇策略 (Supervised Feature Selection Strategies)

* 根據子集衍生方式區分搜尋方法：

* **包裹方法**（Wrapper Methods）
  - 使用外部搜尋程序選擇不同的預測變數子集進行評估
  - 特徵搜尋過程與模型擬合過程分離
  - 例子：向後或逐步選擇、**基因演算法**（Genetic Algorithms）

* **嵌入方法**（Embedded Methods）
  - 特徵選擇程序自然發生於模型擬合過程中
  - 例子：簡單**決策樹**（Decision Tree）
  - 變數在模型用於分割時被選擇
  - 如果預測變數從未用於分割，預測方程與該變數無關，則被排除

* 主要風險：過擬合
  - 使用包裹方法時尤其如此
  - 當訓練集數據點數量相對於預測變數數量較小時風險增加

### 非監督式選擇方法 (Unsupervised Selection Methods)

* 非監督式選擇方法可對模型性能產生積極影響
* 例如Ames住房數據的鄰里變數：
  - 鄰里變數有28個可能值，轉換為27個二元變數
  - 其中2個鄰里只有一或兩個屬性，占總體不到1%
  - 這種低頻率預測變數可能對某些模型（如線性迴歸）產生有害影響
  - 建議在建模前移除這些變數

### 變數子集搜尋的考量 (Considerations for Variable Subset Search)

* 可能不存在唯一的最佳性能預測變數集
* 存在補償效應：
  - 移除某個看似重要的變數時，模型使用剩餘變數進行調整
  - 在解釋變數之間存在相關性或使用低偏差模型時尤其明顯

* 特徵選擇不應作為確定特徵顯著性的正式方法
* 對評估預測變數對基礎模型或數據集的貢獻：
  - 建議使用更傳統的推論統計方法

  ## 1.5 本書大綱 (An Outline of the Book)

* 本書目標：提供有效工具來發現相關且具預測性的預測變數表達方式
* 這些工具將成為預測建模過程的兩端：
  - 過程開始：探索增強預測變數集的技術
  - 過程結束：提供篩選增強預測變數集的方法，以產生更好的模型

### 各章節內容概述 (Chapter Overview)

* **第2章**：模型與特徵工程過程互動的簡短說明
  - 使用特徵工程和特徵選擇方法改善預測缺血性中風風險的模型能力

* **第3章**：預測模型開發過程回顧
  - 資料分割、驗證方法選擇、模型調優、未來預測性能估計
  - 在多個模型的模型建構過程中使用反饋循環的指導

* **第4章**：資料探索性視覺化
  - 理解預測變數之間以及預測變數與響應變數之間關係的視覺化技術
  - 評估個別預測變數特性（偏度、缺失值模式）的視覺化方法
  - 評估模型擬合不良的圖形方法

* **第5章**：**類別型預測變數**（Categorical Predictors）編碼方法
  - 表示類別型預測變數的標準技術
  - 類別型預測變數的特徵工程方法，如**特徵雜湊**（Feature Hashing）
  - 處理類別型預測變數中罕見水平的實用問題
  - 為樹狀和規則型模型創建**虛擬變數**（Dummy Variables）的影響
  - 基於日期的預測變數處理（可視為類別型預測變數）

* **第6章**：**數值型預測變數**（Numeric Predictors）工程
  - 單變量和多變量轉換作為尋找更好形式的第一步
  - 使用**基底展開**（Basis Expansions）如樣條函數（Splines）創建更好的表示
  - 將連續預測變數轉換為類別或序數箱，以減少變異並提高性能
  - 數值預測變數分箱的注意事項

* **第7章**：**交互作用效應**（Interaction Effects）檢測
  - 探索兩個或多個原始預測變數之間交互作用的重要性
  - 確定預測變數之間交互作用的量化工具
  - 評估這些效應重要性的圖形方法
  - 交互作用可估計性的概念探討

* **第8章**：處理**缺失數據**（Missing Data）
  - 探索缺失數據的機制
  - 調查缺失數據模式的視覺化工具
  - 移除或插補缺失數據的傳統和現代工具
  - 評估連續和類別型預測變數的插補方法

* **第9章**：處理**剖面數據**（Profile Data）
  - 處理時間序列（縱向）、細胞-孔板、圖像等特殊結構數據
  - 金融、製藥、情報、交通和天氣預報領域常見的數據類型
  - 介紹**偏最小平方法**（Partial Least Squares）等自然處理此類數據的工具
  - 在建模前總結或壓縮剖面數據的技術

* **第10-12章**：**特徵選擇**（Feature Selection）策略
  - 特徵選擇的目標
  - 無關預測變數的後果
  - 與通過**正則化**（Regularization）進行選擇的比較
  - 如何避免特徵選擇過程中的過擬合

  # 2 說明性案例：預測缺血性中風風險 (Illustrative Example: Predicting Risk of Ischemic Stroke)

* 本章節作為特徵工程的入門，展示類似圖1.4所示的建模過程
* 為說明目的，本例將聚焦於探索、分析擬合和特徵工程，通過單一模型（邏輯迴歸）視角

## 研究背景與假設 (Background and Hypothesis)

* 傳統上，動脈狹窄（阻塞）程度用於識別中風風險患者
* 阻塞充分（>70%）的患者通常建議進行手術干預
* 歷史證據表明阻塞程度本身實際上是未來中風的較差預測因子
* 理論認為：同等大小的阻塞，**斑塊阻塞的組成**也與中風風險相關
  - 大型但穩定且不易破裂的斑塊可能比小型但不穩定的斑塊風險更低

## 研究數據集 (Dataset)

* 選擇了126位具有不同程度頸動脈阻塞的患者歷史數據
  - 其中44位患者阻塞大於70%
* 所有患者接受了**電腦斷層血管造影**（Computed Tomography Angiography, CTA）
* 使用Elucid Bioimaging的vascuCAP™軟件分析圖像，生成解剖結構估計：
  - 狹窄百分比
  - 動脈壁厚度
  - 組織特性（如富含脂質的壞死核心和鈣化）

## 圖像特徵與測量 (Imaging Features and Measurements)

* **圖2.1(a)**：表示嚴重狹窄的頸動脈
  - 軟件可計算面積（MaxStenosisByArea）和直徑（MaxStenosisByDiameter）的最大橫截面狹窄
  - 灰色區域代表提供動脈壁結構支持的大分子，可通過面積量化（MATXArea）

* **圖2.1(b)**：顯示嚴重狹窄和鈣化斑塊（綠色）及富含脂質的壞死核心（黃色）
  - 斑塊和富含脂質的壞死核心被認為會增加中風風險
  - 可通過體積（CALCVol和LRNCVol）和最大橫截面積（MaxCALCArea和MaxLRNCArea）量化

* **圖2.1(c)**：顯示嚴重狹窄和向外的動脈壁生長
  - 頂部箭頭表示最大狹窄的橫截面
  - 底部箭頭表示最大正壁重塑的橫截面
  - **重塑比例**（Remodeling Ratio）：測量動脈壁，比例小於1表示壁收縮，大於1表示壁生長
  - 大比例的冠狀動脈與破裂相關

## 阻塞與中風結果 (Blockage and Stroke Outcome)

* 表2.1顯示阻塞分類與中風結果的關聯
* 基於卡方關聯檢驗（p = 0.42），關聯不具統計顯著性
* 表明阻塞分類本身可能不是中風結果的良好預測因子

## 研究目標與額外數據 (Study Objectives and Additional Data)

* 如果斑塊特性對評估中風風險重要，成像軟件提供的測量可能有助於改善中風預測
* 改善預測能力可幫助醫生做出更好的患者管理或臨床干預決策：
  - 有大型（阻塞>70%）但穩定斑塊的患者可能不需要手術干預
  - 有較小但不穩定斑塊的患者可能需要手術干預或更積極的藥物治療

* 每位患者的數據還包括常見的臨床特徵：
  - 是否有心房顫動
  - 冠狀動脈疾病
  - 吸煙史
  - 性別和年齡等人口統計學資料

## 分析方法 (Analysis Approach)

* 將訓練模型使用風險預測因子、成像預測因子及兩者組合
* 探索這些特徵的其他表示方式，以提取有益的預測信息
* 首先評估容易收集的臨床風險因子（不需要昂貴的成像技術）

## 2.1 資料分割 (Splitting)

* 在建立模型前，需將數據分割為兩部分：
  - **訓練集**（Training Set）：用於開發模型、預處理預測變數和探索關係
  - **測試集**（Test Set）：作為預測變數集/模型組合性能的最終評判

* **分層**（Stratified）分割方法：
  - 在每個結果類別中進行隨機分割
  - 保持中風患者的比例大致相同（見表2.2）
  - 原始數據集的70%分配給訓練集

* **表2.2：按訓練和測試分割的中風結果分布**
  | 數據集 | 中風 = 是 (n) | 中風 = 否 (n) |
  | ------ | ------------- | ------------- |
  | 訓練集 | 51% (45)      | 49% (44)      |
  | 測試集 | 51% (19)      | 49% (18)      |

* 分層抽樣的優點：
  - 確保訓練和測試集具有相似的結果分布
  - 減少樣本偏差的風險
  - 提高最終模型評估的可靠性

  ## 2.2 預處理 (Preprocessing)

* 建模過程的首要步驟是了解預測變數的重要特性：
  - 個別分佈
  - 每個預測變數中缺失值的程度
  - 預測變數中潛在的異常值
  - 預測變數之間的關係
  - 每個預測變數與結果變數的關係

* 當預測變數數量增加時，仔細檢視每個變數的能力迅速下降
  - 自動化工具和視覺化可實施良好實踐
  - 參考 Kuhn (2008) 和 Wickham and Grolemund (2016)

### 處理缺失值 (Handling Missing Values)

* 數據集中僅有4個缺失值（所有受試者和預測變數）
* 許多模型無法容忍任何缺失值，因此必須採取行動
* 使用**中位數插補**（Median Imputation）替換缺失值：
  - 簡單、無偏的方法
  - 適用於相對少量的缺失（但非最佳方案）
  - 更多插補技術將在第8章討論

### 預測變數的探索 (Exploration of Predictors)

* 數據集夠小，可進行手動探索
* 成像預測變數的單變量探索發現許多有趣特性：
  - 預測變數進行了**均值中心化**和**單位方差縮放**以便直接視覺比較
  - 許多成像預測變數具有長尾分佈（正偏分佈）
  
* 範例：富含脂質壞死核心的最大橫截面積（MaxLRNCArea）
  - 圖2.2a 顯示原始偏斜分佈
  - 初看可能認為偏度和高度異常值是由少數患者引起
  - 但偏度通常是數據基本分佈的結果，不是異常值

* 解決方案：數據轉換
  - 簡單的**對數轉換**（Log-transformation）
  - 或更複雜的**Box-Cox**或**Yeo-Johnson轉換**（第6.1節）
  - 使數據在近似對稱的尺度上，消除異常值的外觀（圖2.2b）
  - 對於指數增長的測量特別適用
  - 脂質面積自然地乘法增長（面積計算的定義）

### 處理高相關性預測變數 (Handling Correlated Predictors)

* 移除與其他預測變數高度相關（r² > 0.9）的預測變數
* 圖2.3熱圖顯示成像預測變數之間的相關性
  - 列和行順序由聚類算法決定
  - 三對預測變數顯示不可接受的高相關性（紅色方框）：
    1. 血管壁體積（WallVol）和基質體積（MATXVol）
    2. 最大橫截面壁面積（MaxWallArea）和最大基質面積（MaxMATXArea）
    3. 基於面積的最大橫截面狹窄（MaxStenosisByArea）和基於直徑的最大橫截面狹窄（MaxStenosisByDiameter）
  
* 對最後一對高相關的理解：面積計算是直徑的函數
* 其他接近閾值的中度高相關變數對：
  - 鈣化體積（CALCVol）和最大橫截面鈣化面積（MaxCALCArea）(r = 0.87)
  - 富含脂質壞死核心的最大橫截面積（MaxLRNCArea）和富含脂質壞死核心的體積（LRNCVol）(r = 0.8)

* 相關性閾值是任意的，可能需要根據問題和使用的模型調整
  - 第3章包含更多關於此方法的詳細信息

  ## 2.3 探索 (Exploration)

* 下一步是探索潛在的預測關係：
  - 個別預測變數與結果之間的關係
  - 預測變數對之間與結果的關係

* 確保不過度解釋小數據集中的趨勢：
  - 使用**重抽樣**（Resampling）技術
  - 採用**重複10折交叉驗證**（Repeated 10-fold Cross-validation）
  - 創建訓練集的50個變種，用於評估所有分析
  - 提供防止過擬合的保護機制

### 模型比較方法論 (Model Comparison Methodology)

* 傳統方法缺點：在整個數據集上進行統計假設檢驗，可能導致過擬合
* 替代方法：比較兩個模型（M₁和M₂）的演算法（圖像1）：
  1. 對每個重抽樣樣本，使用90%擬合兩個模型
  2. 用兩個模型預測剩餘10%
  3. 計算兩個模型的ROC曲線下面積
  4. 確定兩個AUC值的差異
  5. 使用單側t檢定測試M₂是否優於M₁
  
* 90%和10%數值源於使用10折交叉驗證

### 風險預測變數分析 (Risk Predictors Analysis)

* 比較兩個邏輯迴歸模型：
  - 簡單模型（僅包含截距項）
  - 複雜模型（包含風險集中的單個預測變數）
  
* 表2.3（圖像2）顯示每個風險預測變數相對於空模型的ROC改善
* 多個預測變數提供顯著但有限的改善：
  - **冠狀動脈疾病**（CoronaryArteryDisease）：0.079改善，p=0.0003
  - **糖尿病病史**（DiabetesHistory）：0.066改善，p=0.0003
  - **高血壓病史**（HypertensionHistory）：0.065改善，p=0.0004
  - **年齡**（Age）：0.083改善，p=0.0011
  - **心房顫動**（AtrialFibrillation）：0.044改善，p=0.0013

### 成像預測變數分析 (Imaging Predictors Analysis)

* 圖2.4（圖像3）展示每個成像預測變數與中風結果的散點圖
* 與中風結果關聯最強的變數：
  - 目標所有橫截面中的最厚壁厚（MaxMaxWallThickness）
  - 最大橫截面壁重塑比率（MaxRemodelingRatio）
  
* MaxRemodelingRatio分析：
  - 中風類別間平均值有顯著差異
  - 但分布仍有相當重疊
  - 圖2.5（圖像4）顯示其ROC曲線
  - 顯示有一定信號，但可能不足以作為單獨的預後工具

### 交互作用探索 (Interaction Exploration)

* 探索預測變數之間的配對交互作用：
  - 數值預測變數的交互作用通過乘法生成
  - 從成像預測變數對中創建了171個潛在交互作用項
  
* 圖2.6（圖像5）展示：
  - x軸：交互作用項導致的ROC改善
  - y軸：改善的負對數p值（值越大越顯著）
  - 點的大小：主效應模型的基線ROC曲線下面積
  
* 171個交互作用項中，18個提供了相對於主效應的改善（p < 0.2）

* MaxRemodelingRatio與MaxStenosisByArea的交互作用：
  - 圖2.7（圖像6）面板(a)：兩個預測變數的散點圖，按中風結果著色
  - 等值線代表兩個預測變數之間的等效乘積值
  - 未發生中風的患者通常具有較低的乘積值
  - 發生中風的患者通常具有較高的乘積值
  - 實際意義：顯著阻塞結合血管壁向外生長增加中風風險
  - 面板(b)：這種交互作用的箱形圖顯示中風結果類別之間的分離比任一單獨預測變數更強

## 2.4 跨集預測建模 (Predictive Modeling Across Sets)

* 此階段可探索至少五種預測變數組合的預測能力：
  - 僅原始風險集
  - 僅成像預測變數
  - 風險和成像預測變數結合
  - 成像預測變數及其交互作用
  - 風險、成像預測變數及其交互作用

### 模型選擇與考量 (Model Selection and Considerations)

* 醫師偏好**邏輯迴歸**（Logistic Regression）模型：
  - 具有內在可解釋性
  - 屬於高偏差、低變異模型
  - 預測性能往往低於低偏差、高變異模型
  - 包含相關或非資訊性預測變數會降低其性能
  - 需識別最相關預測變數來找到最佳子集

### 特徵選擇方法論 (Feature Selection Methodology)

* 使用**遞迴特徵消除**（Recursive Feature Elimination, RFE）確定最佳預測變數集：
  - 簡單的向後選擇程序
  - 初始使用最大模型，並對每個預測變數按重要性排名
  - 使用迴歸係數絕對值判斷重要性（在預測變數被中心化和縮放後）
  - 逐步移除最不重要的預測變數，重新擬合模型並評估性能
  - 每次模型擬合時，預測變數都經過Yeo-Johnson轉換、中心化和縮放

* 處理預測變數間相關性：
  - 相關性可能導致邏輯迴歸係數不穩定
  - 使用額外變數過濾器移除最小預測變數集，使無成對相關性大於0.75
  - 分析使用和不使用此步驟的數據預處理結果

* 結合重抽樣方案與RFE過程：
  - 向後選擇在訓練集的50個不同90%子集上執行
  - 使用剩餘10%評估移除預測變數的效果
  - 在整個訓練集上執行最終RFE，並在最佳大小處停止
  - 目的是減少小數據集過擬合風險
  - 所有預處理步驟在重抽樣步驟內進行，相關性過濾器可能為每個重抽樣選擇不同變數

### RFE應用於不同預測變數集 (RFE Application to Different Predictor Sets)

* 風險預測變數集（8個預測變數）：
  - 僅考慮主效應時，偏好完整8個預測變數集
  - 加入所有28個配對交互作用時，額外交互作用損害模型性能
  - 基於重抽樣，13個預測變數集最佳（其中11個為交互作用）
  - 應用相關性過濾器時，主效應模型不受影響，交互作用模型最多18個預測變數
  - 過濾器對此預測變數集無幫助

* 成像預測變數集（19個預測變數）：
  - 數據集偏好沒有之前發現的交互作用且使用相關性過濾器的模型
  - 似乎反直覺，但非交互作用項可能替代或補償最重要交互作用項提供的信息
  - 迄今為止最佳模型基於7個經過過濾的成像主效應

* 所有預測變數組合：
  - 不使用相關性過濾器時，性能一般，交互作用和主效應模型無明顯差異
  - 應用過濾器後，數據強烈偏好主效應模型（包含所有10個通過相關性過濾的預測變數）

### 最終模型與評估 (Final Model and Evaluation)

* 最終選擇的預測變數集（7個成像預測變數）：
  - MaxLRNCArea
  - MaxLRNCAreaProp
  - MaxMaxWallThickness
  - MaxRemodelingRatio
  - MaxCALCAreaProp
  - MaxStenosisByArea
  - MaxMATXArea

* 表2.4（圖像2）顯示在所有50個重抽樣中，7變數模型中預測變數的選擇頻率：
  - 選擇結果相當一致，特別考慮到訓練集很小
  - 前四個變數（MaxLRNCAreaProp、MaxMaxWallThickness、MaxCALCAreaProp、MaxRemodelingRatio）被選中頻率最高

* 測試集表現：
  - ROC曲線下面積為0.69
  - 低於重抽樣估計的0.72
  - 但高於估計的90%下限（0.674）

## 2.5 其他考量 (Other Considerations)

* 本章所呈現的方法並非處理這些數據的唯一方法
* 存在多種替代方法和值得探討的問題：

### 替代建模方法 (Alternative Modeling Approaches)

* 例如，如果評估邏輯迴歸，可以考慮`glmnet`模型（Hastie, Tibshirani, and Wainwright 2015）
  - 將特徵選擇整合到邏輯迴歸擬合過程中

### 未探索的方向與潛在問題 (Unexplored Directions and Potential Questions)

* 合理的疑問包括：
  - 為何僅預處理成像預測變數？
  - 為何未探索風險預測變數之間或風險預測變數與成像預測變數之間的交互作用？
  - 為何在原始預測變數而非預處理後的預測變數上構建交互作用項？
  - 為何未採用不同的建模技術或特徵選擇程序？

### 替代方法的可能性 (Possibilities with Alternative Approaches)

* 可能有不同的預處理方法、不同的預測變數組合或不同的建模技術能帶來更好的預測性
* 不同的方法可能產生不同的結果和洞見

### 核心要點 (Key Takeaway)

* 本章主要目的：說明花更多時間（有時是大量時間）調查預測變數及其關係可以幫助改善模型預測性
* 這在預測性能的邊際改善能帶來顯著收益時尤為重要
* 特徵工程和選擇過程的投資通常會產生實質性回報

# 3 預測建模過程回顧 (A Review of the Predictive Modeling Process)

* 在深入探討特定的建模方法和技術之前，需要先討論和定義一些必要的主題
* 這些主題對於實證建模而言是相當普遍的，包括：
  - 回歸和分類問題的性能測量指標
  - 最佳數據使用方法（包括數據分割和重抽樣）
  - 模型調優的最佳實踐
  - 比較模型性能的建議

## 章節使用的數據集 (Datasets Used in This Chapter)

* 本章使用兩個數據集來說明相關技術：

1. **艾姆斯房價數據**（Ames Housing Price Data）
   - 首次在第1章介紹
   - 用於回歸問題示例

2. **在線約會網站職業分類數據**（Online Dating Site Profession Classification）
   - 基於在線約會網站信息對人的職業進行分類
   - 用於分類問題示例
   - 將在下一節詳細討論

## 3.1 說明性案例：OkCupid個人資料數據 (Illustrative Example: OkCupid Profile Data)

* **OkCupid**是一個服務國際用戶的在線約會網站
* Kim和Escobedo-Land（2015）描述了一個來自舊金山地區超過50,000個個人資料的數據集
* 數據可在`GitHub`存儲庫中找到

### 數據類型 (Data Types)

* 數據包含幾種類型的變數：
  - **開放式文本**：與個人興趣和個人描述相關的文章
  - **單選欄位**：如職業、飲食習慣和教育程度
  - **多選欄位**：如所說語言和編程語言熟練度

* 原始形式中，幾乎所有數據欄位本質上都是離散的：
  - 僅年齡和上次登錄以來的時間為數值型
  - 分類預測變數在擬合模型前轉換為**虛擬變數**（Dummy Variables）（第5章）

### 預測變數結構 (Predictor Structure)

* 本章分析中將忽略開放式文本數據（將在5.6節探討）
* 使用的212個預測變數中包含以下變數群集：
  - 地理位置（鎮，p=3）
  - 宗教信仰（p=13）
  - 星座（p=15）
  - 孩子（p=15）
  - 寵物（p=15）
  - 收入（p=12）
  - 教育（p=32）
  - 飲食習慣（p=17）
  - 超過50個與口語相關的變數

* 有關數據集及其處理方式的更多信息，請參閱該書的GitHub存儲庫

### 預測目標與數據平衡 (Prediction Goal and Data Balance)

* 目標：預測一個人的職業是否屬於**STEM領域**（科學、技術、工程和數學）
* 數據存在中度類別不平衡：
  - 僅18.5%的個人資料從事這些領域工作
  - 雖然不平衡對分析有顯著影響，但本例將主要通過**下採樣**（Down-sampling）規避此問題
  - 下採樣使每個類別的個人資料數量相等

* 關於處理罕見類別的技術詳細描述，請參閱Kuhn和Johnson（2013）第16章

## 3.2 績效測量 (Measuring Performance)

* 雖然常被忽視，但用於評估模型預測效能的指標非常重要，並可能影響結論
* 選擇的指標取決於結果變數類型

### 3.2.1 迴歸指標 (Regression Metrics)

* **均方根誤差**（Root Mean Squared Error, RMSE）
  - 計算方法：計算觀測值與預測值之間差異（殘差）的平方平均值，然後取平方根
  - 優點：結果以原始測量單位表示
  - 解釋：樣本從其觀測值到預測值的平均距離
  - 規則：RMSE越低，模型預測能力越佳

* **決定係數**（Coefficient of Determination, R²）
  - 計算方法：觀測值與預測值之間的標準相關係數的平方
  - 優點：對線性模型有直觀解釋：可被模型解釋的結果總變異比例
  - 特點：接近1.0表示幾乎完美擬合，接近零表示預測與結果無線性關聯
  - 優勢：無單位，便於比較不同結果

* **R²的問題**：
  - 主要問題：是相關性而非準確性的度量
  - 模型可能與觀測值有強線性關係，但不符合45度一致線
  - 現象舉例：樹狀集成方法（如隨機森林、提升樹等）在結果一端低估而另一端高估
  - 當結果變異大時，可能顯示過於樂觀的結果
  - 少數離群值可能人為增加R²值

* **圖3.1**顯示R²問題：
  - 芝加哥列車乘客數據模型R²估計為0.9，表面看似極佳
  - 但高值主要由於乘客數工作日高、週末低的固有雙峰性質
  - 雙峰結果增加結果變異，進而增加R²
  - 部分殘差大於10,000人次，RMSE為3,853人次
  - 藍線（觀測值與預測值的線性迴歸擬合）與黑線（一致線）比較顯示模型在小值低估、大值高估

* **一致相關係數**（Concordance Correlation Coefficient, CCC）
  - Lawrence和Lin（1989）開發，解決相關係數過於樂觀的問題
  - 定義：普通相關係數與一致線偏差測量的乘積
  - 偏差係數範圍0至1，1表示數據落在一致線上
  - 可視為帶懲罰的相關係數
  - 數據與一致線偏離越遠，偏差係數越小

* **穩健指標**（Robust Metrics）
  - RMSE和R²對極端值非常敏感（基於殘差平方）
  - 穩健技術尋找數據多數部分的數值摘要
  - 方法：降低極端樣本權重或轉換原始值
  - 範例：等級相關、中位數絕對偏差（MAD）、絕對誤差

### 3.2.2 分類指標 (Classification Metrics)

* 兩種類型：
  - 基於定性類別預測（如STEM或其他）
  - 使用預測類別機率（如Pr[STEM]=0.254）

* **混淆矩陣**（Confusion Matrix）
  - 觀測類別與預測類別的簡單交叉表格
  - 表3.1顯示OkCupid數據的混淆矩陣
  - 對角線上為正確預測樣本

* **分類準確度**（Classification Accuracy）
  - 定義：正確預測結果的比例
  - 例子：0.78 = (5134 + 25257)/(5134 + 6385 + 2033 + 25257)
  - 問題：類別不平衡時可能產生誤導（如預測全部非STEM可達0.82）

* **科恩卡帕係數**（Cohen's Kappa）
  - 考慮類別不平衡，將錯誤率標準化為預期偶然發生的錯誤率
  - 值範圍-1至1，1表示完全一致，接近零表示無關聯
  - 可推廣至多類別問題

* **馬賽克圖**（Mosaic Plot）
  - 用於可視化混淆矩陣（圖3.3）
  - 每個單元格表示為面積與數值成比例的矩形

* **二分類特殊指標**：

  * 敏感度（Sensitivity）/真陽性率：
    - 定義：正確預測的事件比例
    - 計算：5,134/7,167 = 0.716
    - 如果檔案確實是STEM，被正確預測的機率是多少？

  * 特異度（Specificity）：
    - 定義：正確預測非事件的比例
    - 計算：25,257/31,642 = 0.798
    - 假陽性率 = 1 - 特異度（0.202）

  * 精確度（Precision）：
    - 定義：所有預測事件中正確預測的比例
    - 計算：5,134/11,519 = 0.446
    - 如果檔案被預測為STEM，實際是STEM的機率是多少？

* **條件統計與貝葉斯法則**：
  - 敏感度、特異度、精確度均為條件統計量
  - 真正想知道的：Pr[Y = STEM|P = STEM]
  - 貝葉斯法則：Pr[Y|P] = Pr[Y] × Pr[P|Y] / Pr[P] = 先驗 × 似然 / 證據

* **陽性預測值**（Positive Predictive Value, PPV）和**陰性預測值**（Negative Predictive Value, NPV）：
  - PPV：無條件敏感度類比
  - NPV：無條件特異度類比
  - 使用盛行率（先驗機率）進行計算
  - OkCupid資料的PPV = 0.45，NPV = 0.93（假設盛行率0.18）
  - 若全美STEM盛行率為5%，則PPV = 0.16，NPV = 0.98

* **基於機率的指標**：

  * **二項式對數似然統計量**（Binomial Log-likelihood Statistic）：
    - 計算公式：log ℓ = ∑ᵢ₌₁ⁿ ∑ⱼ₌₁ᶜ yᵢⱼlog(pᵢⱼ)
    - 目標：最大化對數似然
    - 當所有樣本以高機率被正確預測時達到最大值

  * **基尼準則**（Gini Criterion）：
    - 計算公式：G = ∑ᵢ₌₁ⁿ ∑ⱼ≠ⱼ′ pᵢⱼpᵢⱼ′
    - 類別機率變異或不純度的測量
    - 應最小化

  * **熵**（Entropy）：
    - 計算公式：H = -∑ᵢ₌₁ⁿ ∑ⱼ₌₁ᶜ pᵢⱼlog₂pᵢⱼ
    - 類別機率變異或不純度的測量
    - 應最小化

* **表3.2**比較：
  - 對數似然使用真實類別信息，以監督方式懲罰不良模型
  - 基尼和熵只懲罰不確定模型（產生大致相等的類別機率）
  - 好模型與壞模型在基尼和熵上值相等，但在對數似然上差異明顯

* **ROC曲線**（圖3.4a）：
  - 考慮所有可能閾值，追蹤敏感度和特異度的變化
  - 繪製假陽性率（1-特異度）與真陽性率
  - 最佳模型緊貼y軸直接前往左上角
  - ROC曲線下面積（AUC）：1為完美，約0.5為無效
  - OkCupid數據AUC為0.839，表示適中良好擬合

* **精確度-召回曲線**（圖3.4b）：
  - 從信息檢索角度更適合
  - 貧弱模型的曲線接近觀測盛行率（此處為0.18）的水平線
  - 曲線下面積用於總結模型性能，最佳值為1.0，最差為盛行率
  - OkCupid數據的曲線下面積為0.603

### 3.2.3 特定情境指標 (Context-Specific Metrics)

* 前述指標可用於開發有效模型，但可能無法回答核心問題
* 例如：廣告點擊預測模型可能需要回答「使用此模型公司將賺多少錢？」
* 貸款例子：可計算預期利潤或損失
* 應讓感興趣的問題引導選擇適當的評估指標
* 可能使用現有通用指標，或需開發特定情境的自定義指標

## 3.3 數據分割 (Data Splitting)

* 建模專案起始的首要決策之一是如何利用現有數據
* 常見技術：將數據分為兩組，稱為**訓練集**（Training Set）和**測試集**（Testing Set）

### 訓練集與測試集的用途 (Purpose of Training and Testing Sets)

* **訓練集**：
  - 用於開發模型和特徵集
  - 作為估計參數的基礎
  - 比較模型和進行其他達成最終模型所需的活動

* **測試集**：
  - 僅在結論階段使用
  - 用於估計模型性能的最終、無偏評估
  - 關鍵點：在此之前不應使用測試集
  - 提前查看測試集結果會產生偏差，因為測試數據將成為模型開發過程的一部分

### 測試集大小考量 (Test Set Size Considerations)

* 很難制定統一的指導方針
* 影響因素包括：
  - 原始樣本池的大小
  - 預測變數的總數量
  - 樣本數（n）與預測變數數（p）的比率
  
* 當樣本池較大時：
  - 一旦訓練集包含「足夠」樣本，分割決策的重要性降低
  - 簡單初始分割的替代方案可能是好主意（見3.4.7節）

* 樣本數與預測變數數比率（n:p）很重要：
  - n遠大於p時，分割數據更有彈性
  - 當n小於p時，即使n看似較大，仍可能遇到建模困難

### 數據分割方法 (Data Splitting Methods)

* **完全隨機抽樣**（Completely Random Sampling）：
  - 最常見的方法
  - 直接實施且通常避免對數據特性產生偏差
  - 問題：當結果變數分布不均勻時可能有問題

* **分層隨機抽樣**（Stratified Random Sampling）：
  - 基於結果變數進行
  - 分類模型：在每個類別內隨機選擇樣本
  - 確保結果變數的頻率分布在訓練集和測試集中大致相等
  - 數值結果：可基於四分位數構建人工分層
    * 例如：艾姆斯房價數據可分為四組，每組約230個房屋
    * 在四個組內進行訓練/測試分割，然後合併

* **非隨機抽樣**（Non-random Sampling）：
  - 當有充分理由時使用
  - 例如：數據具有重要時間特性時
  - 可能明智的做法是使用最新數據作為測試集
  - 應用案例：第4.1節討論的芝加哥交通數據

## 3.4 重抽樣 (Resampling)

* 重抽樣方法用於在不使用測試集的情況下評估模型效能
* 產生訓練集的不同版本，用於模擬模型在新數據上的表現

### 重抽樣的基本概念 (Basic Concepts of Resampling)

* 每種重抽樣技術產生數據的兩個子集：
  - **分析集**（Analysis Set）：用於建立模型
  - **評估集**（Assessment Set）：用於衡量性能
  - 類似於訓練集和測試集的概念（圖3.5）

* 重抽樣的基本單位是**獨立實驗單元**（Independent Experimental Unit）
  - 例如：艾姆斯數據每棟房屋都是獨立的
  - 若每個客戶有多行數據，則整個客戶及其所有數據一起分配

### 3.4.1 V折交叉驗證及其變體 (V-Fold Cross-Validation and Its Variants)

* **基本V折交叉驗證**：
  - 創建V個訓練集的不同版本，每個大小大致相同
  - 每個評估集包含訓練集的1/V，分析集包含其餘部分
  - 循環方式計算V個性能估計值，最終取平均值
  - 圖3.6展示20個樣本的10折交叉驗證

* **OkCupid數據案例**：
  - 使用分層10折交叉驗證
  - 訓練集38,809個檔案，每個評估集3,880個不同檔案
  - ROC曲線下面積範圍從0.83到0.854，平均值為0.839

* **重複V折交叉驗證**：
  - 減少基本V折交叉驗證的變異性
  - 使用R次重複，創建RV個重抽樣
  - 最終方差減少約√R

* **特殊變體**：
  - **留一交叉驗證**（Leave-one-out）：V等於訓練集大小，僅適用於極小訓練集
  - **分組V折交叉驗證**：按組（如客戶）而非單個觀測值進行重抽樣

### 3.4.2 蒙特卡洛交叉驗證 (Monte Carlo Cross-Validation)

* 與V折交叉驗證不同，評估集可能有重疊
* 每次重抽樣，π比例的訓練集進入分析集，剩餘樣本進入評估集
* 重複B次，取B次結果的平均值
* 圖3.6顯示10次重抽樣和π=0.90的蒙特卡洛交叉驗證

### 3.4.3 自助法 (The Bootstrap)

* 自助法重抽樣：與訓練集大小相同的**有放回**簡單隨機樣本
* 特點：
  - 訓練集成員在自助樣本中至少出現一次的機率為63.2%
  - 自助樣本作為分析集
  - 評估集（袋外樣本）由未包含在自助樣本中的訓練集成員組成
* 圖3.7顯示20個樣本數據集的10個自助樣本

### 3.4.4 滾動原點預測 (Rolling Origin Forecasting)

* 專門用於時間序列數據或具有強時間成分的數據集
* 適用場景：數據存在季節性或其他慢性趨勢
* 方法：
  - 第一個分析集由前M個訓練集點組成
  - 評估集包含接下來的N個訓練集樣本
  - 每次保持數據集大小相同，但增量分析集
* 圖3.8展示使用10個數據點進行分析，隨後2個樣本用於評估的重抽樣
* 變體：
  - 分析集大小可累積增長
  - 可跳過迭代以減少重抽樣次數
  - 對於不均勻抽樣的數據，可按時間增量而非數據集行增量移動

### 3.4.5 驗證集 (Validation Sets)

* 介於訓練集和測試集之間的概念
* 源自神經網絡領域，用於確定訓練中的錯誤率
* 通常是訓練集的小隨機子集，用於估計模型訓練時的性能
* 不能替代測試集（或評估集），因為驗證數據引導訓練過程

### 3.4.6 重抽樣的變異與偏差 (Variance and Bias in Resampling)

* **變異**（Variance）：
  - 衡量重複同一重抽樣方案多次時結果的分散程度
  - 固定訓練集大小和重抽樣次數，V折交叉驗證變異性最大，自助法變異性最小

* **偏差**（Bias）：
  - 重抽樣方案能夠接近真實性能參數的能力
  - 當分析集數據量減少時，重抽樣估計的偏差增加
  - 自助法偏差最大（約36.8%的訓練集用於評估），且通常是悲觀偏差
  - V折交叉驗證偏差較低，特別是V≥10時

* 圖3.9圖形表示了重抽樣方案的變異和偏差
* 建議：對於不大的訓練集，使用5次左右重複的10折交叉驗證

### 3.4.7 重抽樣應包含什麼？ (What Should Be Included Inside of Resampling?)

* 重抽樣必須包含建模過程中所有可能顯著影響模型效能的步驟：
  - 預測變數轉換
  - 預處理或過濾步驟
  - 特徵選擇方法
  
* 可豁免的操作：
  - 小範圍的中位數插補
  - 中心化和縮放
  
* **信息洩露**（Information Leakage）問題：
  - 定義：測試集數據直接或間接用於訓練過程
  - 導致過於樂觀的結果，無法在未來數據點上複製
  - 例如：時間序列移動平均平滑處理可能不經意引入測試集信息
  - 解決方法：僅使用訓練數據點開發預處理技術，然後應用於未來數據

* 大數據的替代數據使用方案：
  - 可創建多個分割用於特定目的
  - 例如：使用特定數據分割確定相關預測變數，再用訓練集建模
  - 可減少在重抽樣中包含昂貴特徵選擇步驟的需要

## 3.5 調整參數與過擬合 (Tuning Parameters and Overfitting)

* 許多模型包含**調整參數**（Tuning Parameters）或**超參數**（Hyperparameters）
  - 這些參數無法直接從數據估計
  - 對模型非常重要，通常控制模型複雜度
  - 影響模型的變異-偏差權衡

### K最近鄰模型範例 (K-Nearest Neighbor Example)

* **K最近鄰模型**（K-nearest Neighbor）工作原理：
  - 儲存訓練集數據
  - 預測新樣本時，找出K個距離最近的訓練集點
  - 使用這些鄰居的結果做出預測

* **K值的影響**：
  - 控制模型複雜度
  - 類似於第1.2.5節中移動平均討論，控制模型的變異和偏差
  - K很小時：過擬合風險最大，因為僅使用極少值進行預測，對數據變化最敏感
  - K過大時：使用過多潛在不相關的數據點進行預測，導致欠擬合

### 實際案例演示 (Practical Demonstration)

* 圖3.10展示艾姆斯一個測試集房屋樣本（藍色）與其訓練集中五個最近鄰居（紅色）
* 測試集樣本售價：$176,000
* 鄰居價格（從最近到最遠）：$175,000、$128,000、$100,000、$120,000、$125,000

* **不同K值的影響**：
  - K = 1：模型與真實房價相差$900（僅使用最近的$175,000鄰居）
    * 展示了第1.2.1節引入的過擬合概念
    * 模型過於激進地使用訓練集模式預測新數據點
  - K = 5：使用所有五點平均值預測，大幅減少誤差至$-46,400
    * 註：計算方式為(175K+128K+100K+120K+125K)/5 = 129.6K，與實際176K相比的誤差

### 調整參數的複雜性 (Complexity of Tuning Parameters)

* 一些模型可能有多個調整參數
* K最近鄰模型的其他可能參數：
  - 不同距離度量
  - 不同加權方案（使遠點對預測影響較小）

### 選擇最佳參數值 (Selecting Optimal Parameter Values)

* 需要搜索程序找到合適的調整參數值
* 需要獲得良好、可泛化的性能測量方法
* 重複使用測試集進行這些問題是有問題的（會失去其公正性）
* 通常使用**重抽樣**（Resampling）方法確定最佳參數值
* 下一節將描述確定這些類型參數最佳值的幾種方法

## 3.6 模型最佳化與調優 (Model Optimization and Tuning)

* 尋找最佳調整參數值的方法可分為兩大類：
  - 預先定義要評估的值
  - 增量確定值

### 網格搜索方法 (Grid Search)

* **網格搜索**（Grid Search）是最著名的預定義值評估程序：
  - 指定一組候選調整參數值並進行評估
  - 多個調整參數時，候選參數組合為多維的
  - 建議使用重抽樣評估每個不同參數值組合
  - 選擇「最佳」調整參數組合後，用整個訓練集擬合最終模型
  - 通常選擇實證結果最佳的候選方案

* **K最近鄰模型範例**（OkCupid資料）：
  - 模型需要確定鄰居數量K
  - 預定義候選集為K = 1, 3, ..., 201
  - 結合10折交叉驗證，使用380個臨時模型確定良好的K值
  - 圖3.11顯示K = 201時ROC曲線下面積最大（0.806）
  - 圖中每個黑點代表10個不同模型（使用訓練集不同90%）的平均性能

### 多調整參數處理 (Handling Multiple Parameters)

* 當模型有多個調整參數時的處理方法：
  - **多維網格搜索**：評估候選參數組合的網格（可能效率低）
  - **隨機搜索**（Random Search）：為每個參數定義可能值範圍，並隨機抽樣多維空間
  - 隨機搜索在參數數量大且無先驗知識時特別有益
  - 適用於**神經網絡**（Neural Networks）、**梯度提升機**（Gradient Boosting Machines）等模型

* **神經網絡模型範例**（OkCupid數據）：
  - 使用單層前饋神經網絡預測STEM領域概率
  - 主要調整參數包括：
    1. **隱藏單元數量**（Number of Hidden Units）：控制複雜度（範圍2-20）
    2. **激活函數**（Activation Function）：連接網絡不同部分的非線性函數（選項：S型曲線、tanh、ReLU）
    3. **丟棄率**（Dropout Rate）：訓練迭代中隨機將係數設為零的比率（範圍0-80%）
  
  - 神經網絡係數擬合的相關參數：
    1. **批量大小**（Batch Size）：每個迭代中隨機暴露給優化過程的訓練集數據點數量（範圍10-40,000）
    2. **學習率**（Learning Rate）：控制參數估計迭代中下降率（範圍0-1）
    3. **衰減率**（Decay Rate）：隨時間降低學習率（範圍0-1）
    4. **均方根梯度縮放因子**（Root Mean Square Gradient Scaling Factor, ρ）：控制梯度被近期平方梯度值歸一化的程度（範圍0-1）

  - 隨機創建20個七維調整參數組合，每個都使用10折交叉驗證評估
  - 表3.3顯示最佳設置ROC曲線下面積為0.837

### 自適應搜索方法 (Adaptive Search Methods)

* 不同於預先指定參數的網格搜索和隨機搜索，還有其他自適應方法：
  - **非線性搜索方法**（Nonlinear Search Methods）：
    * **Nelder-Mead單純形搜索**（Nelder-Mead Simplex Search）
    * **模擬退火**（Simulated Annealing）
    * **遺傳算法**（Genetic Algorithms）
  - 這些方法徹底搜索網格空間但計算成本高

* **貝葉斯優化**（Bayesian Optimization）：
  - 首先評估初始樣本池（使用網格或隨機搜索）
  - 創建單獨模型預測性能作為調整參數的函數
  - 推薦下一個要評估的候選集
  - 評估新點後，更新模型並繼續迭代

### 重抽樣結果解釋的注意事項 (Interpreting Resampling Results)

* **優化偏差**（Optimization Bias）風險：
  - 基於結果選擇最佳設置並用這些值表示模型性能可能導致偏差
  - 可能會高估模型的真實性能
  - 嵌套重抽樣程序可用於減輕這些偏差

* 參考 Boulesteix 和 Strobl (2009) 獲取更多信息

## 3.7 使用訓練集比較模型 (Comparing Models Using the Training Set)

* 在多個模型競爭時，需要進行正式評估以了解性能差異是否超出隨機預期範圍
* 建議對所有評估的模型使用相同的重抽樣，以便進行公平比較
* 這允許在使用測試集之前對模型進行正式比較

### 配對比較方法 (Paired Comparison Method)

* **OkCupid資料案例**：比較邏輯迴歸與神經網路模型
  - 兩個模型使用相同的重抽樣進行擬合和評估
  - 形成10個配對比較（10折交叉驗證）
  - 表3.4顯示每個重抽樣的具體ROC結果及其配對差異
  - 兩組值之間的相關性為0.96，表明結果中可能存在重抽樣到重抽樣的效應

* **表3.4：預測OkCupid數據的兩個模型的匹配重抽樣結果**
  |      | ROC估計值 |          |        |
  | ---- | --------- | -------- | ------ |
  |      | 邏輯迴歸  | 神經網絡 | 差異   |
  | 折1  | 0.830     | 0.827    | -0.003 |
  | 折2  | 0.854     | 0.853    | -0.002 |
  | 折3  | 0.844     | 0.843    | -0.001 |
  | 折4  | 0.836     | 0.834    | -0.001 |
  | 折5  | 0.838     | 0.834    | -0.004 |
  | 折6  | 0.840     | 0.833    | -0.007 |
  | 折7  | 0.839     | 0.838    | -0.001 |
  | 折8  | 0.837     | 0.837    | 0.000  |
  | 折9  | 0.835     | 0.832    | -0.003 |
  | 折10 | 0.838     | 0.835    | -0.003 |

### 統計推斷方法 (Statistical Inference Methods)

* 給定配對差異集，可以進行正式統計推斷比較模型
* 簡單方法：
  - 考慮兩個模型之間的**配對t檢定**（Paired t-test）
  - 或對差異進行普通**單樣本t檢定**（One-sample t-test）
  
* OkCupid案例結果：
  - ROC值的估計差異為-0.003
  - 95%置信區間為(-0.004, -0.001)
  - 顯示模型間存在真實但微小的性能差異

* 此方法曾在第2.3節用於預測中風結果的潛在變數排名

### 方法價值 (Value of the Method)

* 這種技術的價值有兩方面：
  1. 防止測試集在模型開發過程中被使用
  2. 使用多次評估（通過評估集）來衡量差異

* 第二點更為重要：
  - 通過使用多個差異，可以測量性能統計的變異性
  - 單一靜態測試集雖有優勢，但僅代表模型性能的單一實現
  - 無法了解此值的精確度

### 多模型比較 (Multiple Model Comparison)

* 也可以比較兩個以上的模型
* 分析必須考慮重抽樣內相關性：
  - 使用**貝葉斯階層模型**（Bayesian Hierarchical Model）(McElreath 2015)
  - 或**重複測量模型**（Repeated Measures Model）(West and Galecki 2014)

* 方法論來源：
  - 最初由Hothorn等人(2005)提出
  - Benavoli等人(2016)提供了模型間和數據集間重抽樣結果分析的貝葉斯方法

## 3.8 無過擬合特徵工程 (Feature Engineering Without Overfitting)

* 第3.5節討論了使用重抽樣調優模型的方法，核心是在未用於建模的數據上評估參數值
* 這一概念同樣適用於特徵工程活動：
  - 工程新特徵/編碼
  - 決定是否將新項納入模型
  - 應始終有獨立數據評估設計選擇的適當性

### 芝加哥列車數據案例 (Chicago Train Data Example)

* 某些日子的乘客數量被嚴重高估
  - 問題根源：假日和附帶趨勢未在預測變數中得到處理
  - 例如：「週五的聖誕節」等情況
  
* 圖3.12展示了這些新特徵對**支持向量機**（Support Vector Machine, SVM）的影響：
  - 面板顯示重抽樣的兩年評估集預測
  - 虛線表示添加假日預測變數前的預測
  - 實線對應添加這些特徵後的模型
  - 清楚表明這些預測變數在這些時間段內改善了性能
  - 雖有明顯的常識性理由，但仍使用評估集確認結果

### 使用重抽樣驗證趨勢 (Validating Trends with Resampling)

* 假設性情境：探索性數據分析清晰顯示當芝加哥公牛隊和熊隊有客場比賽時乘客量減少
  - 即使這種假設模式在訓練集中有明確信號
  - 重抽樣仍是最佳方法來確定在保留部分訓練數據作為無偏對照時是否成立

### OkCupid數據案例 (OkCupid Data Example)

* 第5.6節中，OkCupid數據用於從文本論文數據中派生關鍵詞特徵
* 方法：
  - 使用訓練集中隨機選擇的小部分發現關鍵詞特徵
  - 這個小子集保留在訓練集中並在模型擬合時正常重抽樣
  - 一些發現數據集包含在訓練中，預期重抽樣估計會略微樂觀偏差
  - 但仍有相當大量未參與特徵發現的數據用於確定其有效性

### 最佳實踐建議 (Best Practice Recommendations)

* 最佳做法是對探索性數據分析中發現的趨勢進行「壓力測試」：
  - 使用重抽樣獲得趨勢或模式是否真實的更客觀感知
  - 當數據豐富時，可以分配單獨的數據集用於發現（與訓練和測試集分開）
  - 這種方法在特徵工程過程中有效降低過擬合風險

# 4 探索性視覺化 (Exploratory Visualizations)

* 建模過程的主要目標是尋找可複製的方法來解釋反應變數的變異
* 前一章討論了發現與反應變數相關的預測變數模式的過程：
  - 選擇重抽樣方案防止過擬合
  - 選擇性能指標
  - 調優和訓練多個模型
  - 比較模型性能以識別最佳模型

## 視覺化探索的重要性 (Importance of Visual Exploration)

* 面對新數據集時，容易直接跳入預測建模過程：
  - 嘗試快速開發符合性能期望的模型
  - 或使用建模結果識別與反應變數相關的最重要預測變數
  
* 然而，如圖1.4所示，應花費足夠時間探索數據
* 本章將介紹視覺化探索數據的方法，展示如何指導特徵工程

## 探索性數據分析的步驟 (Steps in Exploratory Data Analysis)

* 首先創建視覺化以幫助闡明對反應變數的了解：
  - 使用**直方圖**（Histogram）或**箱形圖**（Box Plot）了解反應變數
  - 這些簡單視覺化揭示反應變數的變異量和可能的異常特性
  
* 然後探索預測變數之間以及預測變數與反應變數之間的關係：
  - **散點圖**（Scatter Plots）：個別預測變數與反應變數
  - **成對相關圖**（Pairwise Correlation Plot）：預測變數間
  - **高維預測變數的低維投影**（Projection）
  - **時間序列線圖**（Line Plots）：基於時間的預測變數
  - **迴歸或分類樹的前幾個層級**
  - **熱圖**（Heat Map）：跨樣本和預測變數
  - **馬賽克圖**（Mosaic Plots）：檢查分類變數間的關聯

## 視覺化的價值 (Value of Visualization)

* 這些視覺化提供的洞見應用於指導初始模型
* 最有用的視覺化不一定複雜或難以創建
* 一個簡單的散點圖可能揭示模型無法發現的洞見
* 可能導致創建新預測變數或轉換現有預測變數或反應變數，從而改善模型性能
* 挑戰在於發展如何視覺化探索數據以提取改進信息的直覺

## 持續的視覺化過程 (Continuous Visualization Process)

* 探索性數據分析不應在初始階段停止，而應在建立初始模型後繼續
* 模型建立後，視覺工具可用於：
  - 評估模型擬合不足
  - 評估原始模型中不存在的新預測變數的潛在效力

## 本章內容 (Chapter Content)

* 本章將深入探討建構初始模型前的各種有用視覺化工具
* 部分工具可在模型建立後用於識別可改善模型性能的特徵
* 按照圖1.4的輪廓，將查看建模前和建模過程中的視覺化
* 推薦閱讀Tufte (1990)、Cleveland (1993)和Healy (2018)的優秀數據視覺化資源

## 案例數據集 (Example Datasets)

* 芝加哥列車乘客數據（Chicago Train Ridership）：用於數值視覺化
* OkCupid數據：用於分類視覺化

## 4.1 芝加哥列車乘客數據簡介 (Introduction to the Chicago Train Ridership Data)

* 本節使用芝加哥交通管理局（Chicago Transit Authority, CTA）「L」列車系統的乘客數據（圖4.1）來說明：
  - 探索性視覺化如何成為理解數據集的關鍵部分
  - 視覺化如何用於識別和發現有助於改善模型預測能力的預測變數表達方式

### 數據的實際應用價值 (Practical Value of the Data)

* **短期預測價值**：
  - 預測未來一到兩週的乘客量，確保最佳數量的車廂可用
  - 大都市區工作日乘客量通常強於週末
  - 可能的需求誤解錯誤：
    * 工作日車廂過少：延誤乘客、過度擁擠、產生緊張
    * 週末車廂過多：效率低下、運營成本高、盈利能力低
  - 良好的需求預測有助於CTA更接近最佳滿足需求

* **長期預測價值**：
  - 預測何時需要線路服務
  - 更改停靠頻率以最佳服務乘客
  - 隨著人口變化和需求增強或減弱，增加或取消停靠站

### 數據內容與範圍 (Data Content and Scope)

* **收集範圍**：
  - 2001年1月22日至2016年9月11日
  - 涵蓋126個車站的每日乘客量
  - 乘客量測量：每個車站所有閘機入口的數量
  - 此期間各站每日乘客量差異大，範圍在0至36,323人次/天
  - 為便於展示，乘客量以千人次為單位

* **特定關注點**：Clark/Lake站
  - 位於市中心環路
  - 全系統中乘客量最高的車站之一
  - 服務四條不同線路，覆蓋芝加哥北部、西部和南部

### 預測變數構造 (Predictor Construction)

* **時間序列滯後變數**（Lagged Variables）：
  - 預測目標：未來乘客量
  - 僅有歷史數據可用於預測時
  - 創建滯後14天的預測變數：預測D天時，使用D-14天的數據
  - 必要時可添加其他滯後

* **區域因素變數**（Regional Factors）：
  - **天氣數據**：
    * 與乘客數據同期收集
    * 每小時記錄多種條件：陰天、凍雨、雪等
    * 創建反映雨、雪/冰、雲、風暴和晴天相關條件的預測變數
    * 每個類別由更細粒度的記錄條件合併而成
    * 新預測變數通過計算一天內觀察到條件的百分比來編碼
    * 例如：2012年12月20日，條件記錄為：雪（12.8%）、多雲（15.4%）、風暴（12.8%）和雨（71.8%）
    * 其他每小時天氣數據：溫度、露點、濕度、氣壓、降水量和風速
    * 溫度：總結為每日最低、中位數和最高值，以及每日變化
    * 壓力變化：類似計算
    * 多數情況下，使用每日中位數值總結每小時記錄
    * 如同乘客數據，使用滯後版本天氣數據
    * 共有18個天氣相關預測變數

  - **汽油價格數據**：
    * 2001年至2016年芝加哥地區平均每週汽油價格
    * 來源：美國能源信息管理局（U.S. Energy Information Administration）

  - **失業率數據**：
    * 同期月度失業率
    * 來源：美國人口普查局（United States Census Bureau）

* 這些預測變數的潛在用途將在下文討論
* 第9章將進一步討論此類數據的摘要方法

## 4.2 數值數據的視覺化：探索列車乘客數據 (Visualizations for Numeric Data: Exploring Train Ridership Data)

### 4.2.1 箱形圖、小提琴圖和直方圖 (Box Plots, Violin Plots, and Histograms)

* **單變量視覺化**（Univariate Visualizations）用於理解單一變數的分布
* 常見單變量視覺化工具：
  - **箱形圖**（Box-and-whisker Plots/Box Plots）
  - **小提琴圖**（Violin Plots）
  - **直方圖**（Histograms）

* 理解反應變數分布的重要性：
  - 模型主要目標是理解反應變數的變異
  - 必須了解分布是否對稱、偏斜、多峰或含異常值
  - 分布特性提供模型性能期望的下限
  - 可能指示反應變數在分析前需要轉換
  - 可能提供有關包含或創建特定特徵的線索

* **箱形圖**（圖4.2）：
  - 由John Tukey開發，用於快速評估變數分布
  - 包含最小值、下四分位數、中位數、上四分位數和最大值
  - 對稱分布在四分位數間有相等間距
  - 無法有效識別多峰分布

* **直方圖與小提琴圖**（圖4.3）：
  - 直方圖將數據分入等區間並計算樣本頻率
  - 能看到Clark/Lake站乘客量有兩個峰值
  - 小提琴圖由Hintze和Nelson (1998)開發
  - 通過生成數據密度及其鏡像創建
  - 比箱形圖更能保留分布特性，顯示多峰模式

* 乘客數據分析考量：
  - 是否應在自然單位或對數尺度上建模
  - 自然單位使解釋更容易（RMSE以乘客數計）
  - 對數轉換可確保不會預測負乘客量
  - 數據的雙峰性質使決定困難
  - 最終模型使用自然單位，表現略佳

### 4.2.2 通過分面、顏色和形狀增強視覺化 (Augmenting Visualizations through Faceting, Colors, and Shapes)

* 可通過多種方式向圖形添加額外維度：
  - **分面**（Faceting）：基於某變數將同類圖分割成不同面板
  - **顏色**（Colors）：用不同顏色表示類別或數值
  - **形狀**（Shapes）：用不同形狀區分數據點

* Clark/Lake站乘客量分布案例（圖4.5）：
  - 使用分面和顏色按工作日/週末分割乘客量分布
  - 揭示工作日乘客量明顯高於週末
  - 工作日分布左側有長尾，表明某些工作日乘客量異常低
  - 啟發我們進一步探索異常低值的原因，可能是新特徵的來源

### 4.2.3 散點圖 (Scatter Plots)

* **散點圖**：直接在二維空間展示兩個數值變數關係的圖形
* 用途：
  - 評估預測變數與反應變數之間的關係
  - 發現預測變數對之間的關係
  - 了解新預測變數的潛在用處

* 14天滯後乘客量與當日乘客量的散點圖（圖4.6）：
  - 顯示兩者之間存在強烈線性關係
  - 呈現兩個不同的點群（由於工作日/週末差異）
  - 顯示一些點遠離整體模式
  - 表明14天滯後變數將是預測當日乘客量的關鍵因素
  - 進一步解釋離群點可能導致新的有用特徵

### 4.2.4 熱圖 (Heatmaps)

* **熱圖**（Heatmap）：通用視覺化工具，可顯示兩個分類預測變數的關係
  - x軸和y軸形成網格
  - 網格填充可以是連續變數（使用顏色梯度）或分類變數（使用不同顏色）

* 低工作日乘客量熱圖案例（圖4.7）：
  - 創建月日、年份和工作日乘客量<10,000的指標
  - x軸表示年份，y軸表示月日
  - 紅色方框表示乘客量<10,000的工作日
  - 揭示明確模式：低乘客量出現在美國主要假日期間
    * 年初、1月中旬、2月中旬（直到2007年）
    * 5月底、7月初、9月初、11月底、12月底
  - 兩個不遵循年度模式的異常日子：
    * 2011年2月2日：芝加哥創紀錄低溫-16°F
    * 2014年1月6日：暴風雪傾倒21.2英寸雪

* 修改後的散點圖（圖4.8）：
  - 排除主要美國假日後的14天滯後vs當日乘客量
  - 大部分離群點消失，但仍有少數異常值
  - 2010年6月11日：芝加哥慶祝黑鷹隊贏得斯坦利杯
  - 儘管這類慶祝活動不頻繁，但工程化特徵預測這些異常事件可減少模型誤差

### 4.2.5 相關矩陣圖 (Correlation Matrix Plots)

* **相關矩陣圖**：顯示變數對之間相關性的矩陣形式圖
  - 每個變數在外部x軸和y軸上表示
  - 相關強度由矩陣中相應位置的顏色表示

* 2016年非假日工作日14天滯後乘客量相關矩陣（圖4.9）：
  - 幾乎所有車站乘客量對都呈正相關（紅色）
  - 一個車站低乘客量對應另一車站相對低乘客量
  - 大多數車站對之間相關性極高：
    * 18.7%的預測變數對相關性>0.90
    * 3.1%的相關性>0.95
  - 高相關性表明車站間信息冗餘，可通過過濾技術（第3章）或降維（第6章）處理

* 相關圖組織結構：
  - 基於**層次聚類分析**（Hierarchical Cluster Analysis）
  - 目標：將相似樣本在測量空間中排列在一起
  - 車站間距離基於相關值向量
  - 相關向量相似的車站排列相近
  - **樹狀圖**（Dendrogram）連接基於相關向量近似性的樣本
  - 組織結構有助於發現車站的視覺區分分組
  
* 異常車站案例：
  - x軸最左側的車站組顯示低相關甚至負相關
  - 其中一個站的中位數相關性僅為0.23
  - 這是服務奧黑爾機場的車站，受飛機時刻表影響
  - 與同線路的UIC-Halsted站負相關(-0.46)
  - 第二個最不相似的站是Addison站，受比賽出席率驅動

### 4.2.6 線圖 (Line Plots)

* **線圖**（Line Plot）：散點圖的延伸，適用於時間序列數據
  - x軸為時間，y軸為變數值
  - 相鄰時間點的值以線連接
  - 有助於識別時間趨勢，引導特徵工程

* 芝加哥乘客量時間趨勢（圖4.10）：
  - 計算工作日和週末每月平均乘客量
  - 自2001年以來，工作日和週末乘客量穩步增加
  - 與芝加哥大都市區人口增長一致
  - 每年內部模式：1月至10月增加，然後至12月下降
  - 表明最近（一週或一個月內）的乘客量信息對預測未來乘客量更有用

* 週末乘客量與汽油價格關係（圖4.11和4.12）：
  - 週末乘客量顯示出年度趨勢但某些年份內部變異更大
  - 2008年夏季週末乘客量和汽油價格均達高峰
  - 計算月平均2週滯後汽油價格與Clark/Lake站乘客量的幾何平均值
  - 發現正相關：2001-2014年，汽油價格越高，乘客量越高
  - 2015-2016年因石油供應增加而價格下降，趨勢略有不同
  - 挖掘原始線圖特性發現可解釋乘客量變異的新特徵

### 4.2.7 主成分分析 (Principal Components Analysis)

* 多維數據視覺化挑戰：
  - 可使用顏色、形狀和分面視覺化5-6個維度
  - 但現實數據集往往維度更高
  - 投影技術可將多維壓縮至2-3維：
    * **主成分分析**（Principal Components Analysis, PCA）
    * **偏最小平方法**（Partial Least Squares, PLS）
    * **多維縮放**（Multidimensional Scaling, MDS）

* **主成分分析**（PCA）：
  - 找到最能總結原始數據變異性的變數組合
  - 提供數據的簡化表示
  - 經常識別有助於特徵工程的潛在數據特性
  - 第6.3節將更詳細介紹降維技術

* 14天滯後車站乘客量的PCA（圖4.13）：
  - 第一主成分捕捉76.7%的總體變異性
  - 前兩個主成分捕捉83.1%的變異性
  - 表明車站乘客量信息冗餘，可以更濃縮的方式總結

* PCA分析摘要（圖4.13）：
  - (a)部分：前50個成分累積變異量
  - (b)部分：前兩個主成分的散點圖
    * 第一主成分專注於工作日/週末差異
    * 第二主成分專注於時間變化
  - (c)和(d)部分：主成分與影響最大的潛在變數的關係
  - 確認工作日/週末和年份相對於反應變數的重要性
  - 支持創建簡化數據同時保留關鍵預測信息的新特徵