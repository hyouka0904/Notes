# Python Coint å¥—ä»¶ Cheat Sheet
## æ™‚é–“åºåˆ—åˆ†æèˆ‡æ©Ÿå™¨å­¸ç¿’æ‡‰ç”¨

### ğŸ“š åŸºæœ¬æ¦‚å¿µ

**å…±æ•´åˆï¼ˆCointegrationï¼‰**: å…©å€‹æˆ–å¤šå€‹éå¹³ç©©æ™‚é–“åºåˆ—çš„ç·šæ€§çµ„åˆå¯èƒ½æ˜¯å¹³ç©©çš„ï¼Œé€™ç¨®é—œä¿‚ç¨±ç‚ºå…±æ•´åˆã€‚

### ğŸ”§ å®‰è£èˆ‡å°å…¥

```python
# å®‰è£
pip install statsmodels

# ä¸»è¦å°å…¥
import numpy as np
import pandas as pd
from statsmodels.tsa.stattools import coint, adfuller
from statsmodels.tsa.vector_ar.vecm import coint_johansen
import matplotlib.pyplot as plt
import seaborn as sns
```

### ğŸ“Š å–®ç´”æ™‚é–“åºåˆ—åˆ†æ

#### 1. å¹³ç©©æ€§æª¢å®šï¼ˆADF Testï¼‰

```python
# ADF æª¢å®š - æª¢æŸ¥åºåˆ—æ˜¯å¦å¹³ç©©
def check_stationarity(series, name='Series'):
    result = adfuller(series)
    print(f'=== {name} ADF Test ===')
    print(f'ADF Statistic: {result[0]:.6f}')
    print(f'p-value: {result[1]:.6f}')
    print(f'Critical Values:')
    for key, value in result[4].items():
        print(f'\t{key}: {value:.3f}')
    
    if result[1] <= 0.05:
        print(f"çµè«–: {name} æ˜¯å¹³ç©©çš„ (æ‹’çµ•å–®æ ¹å‡è¨­)")
    else:
        print(f"çµè«–: {name} æ˜¯éå¹³ç©©çš„ (ç„¡æ³•æ‹’çµ•å–®æ ¹å‡è¨­)")
    return result[1] <= 0.05

# ä½¿ç”¨ç¯„ä¾‹
is_stationary = check_stationarity(df['price'], 'Stock Price')
```

#### 2. Engle-Granger å…©æ­¥æ³•å…±æ•´åˆæª¢å®š

```python
# å…©å€‹åºåˆ—çš„å…±æ•´åˆæª¢å®š
def engle_granger_coint(y1, y2, alpha=0.05):
    """
    åŸ·è¡Œ Engle-Granger å…±æ•´åˆæª¢å®š
    è¿”å›: (æª¢å®šçµ±è¨ˆé‡, på€¼, æ˜¯å¦å…±æ•´åˆ)
    """
    coint_stat, p_value, crit_values = coint(y1, y2)
    
    print(f'å…±æ•´åˆæª¢å®šçµ±è¨ˆé‡: {coint_stat:.6f}')
    print(f'p-value: {p_value:.6f}')
    print(f'è‡¨ç•Œå€¼ (5%): {crit_values[1]:.6f}')
    
    is_cointegrated = p_value < alpha
    print(f'çµè«–: {"å­˜åœ¨" if is_cointegrated else "ä¸å­˜åœ¨"}å…±æ•´åˆé—œä¿‚')
    
    return coint_stat, p_value, is_cointegrated

# ä½¿ç”¨ç¯„ä¾‹
stat, pval, is_coint = engle_granger_coint(series1, series2)
```

#### 3. Johansen å¤šè®Šé‡å…±æ•´åˆæª¢å®š

```python
def johansen_test(df, det_order=0, k_ar_diff=1):
    """
    Johansen å…±æ•´åˆæª¢å®š
    det_order: -1 (ç„¡å¸¸æ•¸é …), 0 (æœ‰å¸¸æ•¸é …), 1 (æœ‰è¶¨å‹¢é …)
    """
    result = coint_johansen(df, det_order, k_ar_diff)
    
    # è·¡æª¢å®š (Trace Test)
    print('=== è·¡æª¢å®š (Trace Test) ===')
    trace_stats = result.lr1
    trace_crit = result.cvt
    
    for i in range(len(trace_stats)):
        print(f'r <= {i}: çµ±è¨ˆé‡={trace_stats[i]:.2f}, è‡¨ç•Œå€¼(5%)={trace_crit[i, 1]:.2f}')
        if trace_stats[i] > trace_crit[i, 1]:
            print(f'  -> æ‹’çµ• H0ï¼Œè‡³å°‘å­˜åœ¨ {i+1} å€‹å…±æ•´åˆå‘é‡')
    
    # æœ€å¤§ç‰¹å¾µå€¼æª¢å®š
    print('\n=== æœ€å¤§ç‰¹å¾µå€¼æª¢å®š ===')
    eigen_stats = result.lr2
    eigen_crit = result.cvm
    
    for i in range(len(eigen_stats)):
        print(f'r = {i}: çµ±è¨ˆé‡={eigen_stats[i]:.2f}, è‡¨ç•Œå€¼(5%)={eigen_crit[i, 1]:.2f}')
    
    return result

# ä½¿ç”¨ç¯„ä¾‹
data = pd.DataFrame({'x1': series1, 'x2': series2, 'x3': series3})
johansen_result = johansen_test(data)
```

### ğŸ¤– æ©Ÿå™¨å­¸ç¿’çµåˆæ™‚é–“åºåˆ—åˆ†æ

#### 1. ç‰¹å¾µå·¥ç¨‹ - å…±æ•´åˆç‰¹å¾µ

```python
class CointegrationFeatures:
    def __init__(self, window_size=60):
        self.window_size = window_size
        
    def compute_spread(self, y1, y2):
        """è¨ˆç®—åƒ¹å·®ï¼ˆspreadï¼‰"""
        # OLS å›æ­¸æ‰¾æœ€ä½³ä¿‚æ•¸
        from sklearn.linear_model import LinearRegression
        model = LinearRegression()
        model.fit(y1.values.reshape(-1, 1), y2.values)
        beta = model.coef_[0]
        alpha = model.intercept_
        
        # è¨ˆç®—åƒ¹å·®
        spread = y2 - beta * y1 - alpha
        return spread, beta, alpha
    
    def rolling_coint_pvalue(self, df, col1, col2):
        """æ»¾å‹•çª—å£å…±æ•´åˆ p-value"""
        p_values = []
        
        for i in range(self.window_size, len(df)):
            window_data1 = df[col1].iloc[i-self.window_size:i]
            window_data2 = df[col2].iloc[i-self.window_size:i]
            
            try:
                _, p_value, _ = coint(window_data1, window_data2)
                p_values.append(p_value)
            except:
                p_values.append(np.nan)
        
        return pd.Series(p_values, index=df.index[self.window_size:])
    
    def create_features(self, df, pairs):
        """å‰µå»ºå…±æ•´åˆç›¸é—œç‰¹å¾µ"""
        features = pd.DataFrame(index=df.index)
        
        for col1, col2 in pairs:
            # åƒ¹å·®ç‰¹å¾µ
            spread, beta, alpha = self.compute_spread(df[col1], df[col2])
            features[f'spread_{col1}_{col2}'] = spread
            
            # åƒ¹å·®çµ±è¨ˆç‰¹å¾µ
            features[f'spread_zscore_{col1}_{col2}'] = (
                (spread - spread.rolling(self.window_size).mean()) / 
                spread.rolling(self.window_size).std()
            )
            
            # æ»¾å‹•å…±æ•´åˆ p-value
            features[f'coint_pvalue_{col1}_{col2}'] = self.rolling_coint_pvalue(
                df, col1, col2
            )
        
        return features

# ä½¿ç”¨ç¯„ä¾‹
coint_fe = CointegrationFeatures(window_size=30)
pairs = [('stock1', 'stock2'), ('stock1', 'stock3')]
features = coint_fe.create_features(df, pairs)
```

#### 2. é…å°äº¤æ˜“ç­–ç•¥ ML æ¨¡å‹

```python
class PairTradingML:
    def __init__(self, lookback=60, threshold=0.05):
        self.lookback = lookback
        self.threshold = threshold
        self.model = None
        
    def prepare_data(self, df, pair):
        """æº–å‚™è¨“ç·´æ•¸æ“š"""
        from sklearn.preprocessing import StandardScaler
        
        # åŸºç¤ç‰¹å¾µ
        features = pd.DataFrame(index=df.index)
        
        # åƒ¹æ ¼æ¯”ç‡
        features['price_ratio'] = df[pair[0]] / df[pair[1]]
        
        # å…±æ•´åˆæª¢å®š p-value
        coint_pvals = []
        for i in range(self.lookback, len(df)):
            window = slice(i-self.lookback, i)
            _, pval, _ = coint(df[pair[0]].iloc[window], 
                               df[pair[1]].iloc[window])
            coint_pvals.append(pval)
        
        features['coint_pvalue'] = pd.Series(
            coint_pvals, 
            index=df.index[self.lookback:]
        )
        
        # æŠ€è¡“æŒ‡æ¨™
        for col in pair:
            # ç§»å‹•å¹³å‡
            features[f'{col}_ma20'] = df[col].rolling(20).mean()
            features[f'{col}_ma60'] = df[col].rolling(60).mean()
            
            # RSI
            features[f'{col}_rsi'] = self.calculate_rsi(df[col])
            
            # æ³¢å‹•ç‡
            features[f'{col}_volatility'] = df[col].rolling(20).std()
        
        # æ¨™ç±¤ï¼šæœªä¾†æ”¶ç›Š
        features['future_return'] = (
            (df[pair[0]].shift(-5) / df[pair[0]] - 1) - 
            (df[pair[1]].shift(-5) / df[pair[1]] - 1)
        )
        
        return features.dropna()
    
    def calculate_rsi(self, series, period=14):
        """è¨ˆç®— RSI"""
        delta = series.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def train_model(self, features, target_col='future_return'):
        """è¨“ç·´é æ¸¬æ¨¡å‹"""
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.model_selection import train_test_split
        
        # æº–å‚™è¨“ç·´æ•¸æ“š
        X = features.drop(columns=[target_col])
        y = features[target_col]
        
        # åˆ†å‰²æ•¸æ“š
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, shuffle=False
        )
        
        # è¨“ç·´æ¨¡å‹
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        self.model.fit(X_train, y_train)
        
        # è©•ä¼°
        train_score = self.model.score(X_train, y_train)
        test_score = self.model.score(X_test, y_test)
        
        print(f'è¨“ç·´ RÂ²: {train_score:.4f}')
        print(f'æ¸¬è©¦ RÂ²: {test_score:.4f}')
        
        # ç‰¹å¾µé‡è¦æ€§
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        return feature_importance
    
    def generate_signals(self, features):
        """ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´")
        
        X = features.drop(columns=['future_return'])
        predictions = self.model.predict(X)
        
        # ç”Ÿæˆä¿¡è™Ÿ
        signals = pd.DataFrame(index=features.index)
        signals['prediction'] = predictions
        signals['signal'] = 0
        
        # åªåœ¨å…±æ•´åˆé—œä¿‚é¡¯è‘—æ™‚äº¤æ˜“
        coint_mask = features['coint_pvalue'] < self.threshold
        
        # è²·å…¥ä¿¡è™Ÿï¼ˆé æ¸¬æ­£æ”¶ç›Šä¸”å…±æ•´åˆï¼‰
        signals.loc[
            (predictions > 0.01) & coint_mask, 'signal'
        ] = 1
        
        # è³£å‡ºä¿¡è™Ÿï¼ˆé æ¸¬è² æ”¶ç›Šä¸”å…±æ•´åˆï¼‰
        signals.loc[
            (predictions < -0.01) & coint_mask, 'signal'
        ] = -1
        
        return signals

# ä½¿ç”¨ç¯„ä¾‹
pair_ml = PairTradingML(lookback=60)
features = pair_ml.prepare_data(df, ('AAPL', 'MSFT'))
importance = pair_ml.train_model(features)
signals = pair_ml.generate_signals(features)
```

#### 3. VECM (å‘é‡èª¤å·®ä¿®æ­£æ¨¡å‹) é æ¸¬

```python
from statsmodels.tsa.vector_ar.vecm import VECM

def vecm_forecast(data, coint_rank, steps=10):
    """
    ä½¿ç”¨ VECM æ¨¡å‹é€²è¡Œé æ¸¬
    """
    # å»ºç«‹ VECM æ¨¡å‹
    model = VECM(data, k_ar_diff=1, coint_rank=coint_rank)
    vecm_fit = model.fit()
    
    print(vecm_fit.summary())
    
    # é æ¸¬
    forecast = vecm_fit.predict(steps=steps)
    
    # å°‡é æ¸¬çµæœè½‰æ›ç‚º DataFrame
    forecast_df = pd.DataFrame(
        forecast,
        columns=data.columns,
        index=pd.date_range(
            start=data.index[-1] + pd.Timedelta(days=1),
            periods=steps,
            freq='D'
        )
    )
    
    return vecm_fit, forecast_df

# ä½¿ç”¨ç¯„ä¾‹
# å…ˆç”¨ Johansen æª¢å®šç¢ºå®šå…±æ•´åˆç§©
johansen_result = johansen_test(data)
coint_rank = 1  # æ ¹æ“šæª¢å®šçµæœè¨­å®š

vecm_model, predictions = vecm_forecast(data, coint_rank, steps=30)
```

### ğŸ“ˆ å¯¦æˆ°ç¯„ä¾‹ï¼šå®Œæ•´çš„å…±æ•´åˆåˆ†ææµç¨‹

```python
class CointegrationAnalysis:
    def __init__(self, data):
        self.data = data
        self.results = {}
        
    def full_analysis(self, cols):
        """åŸ·è¡Œå®Œæ•´çš„å…±æ•´åˆåˆ†æ"""
        print("=== 1. å¹³ç©©æ€§æª¢å®š ===")
        for col in cols:
            is_stationary = check_stationarity(self.data[col], col)
            self.results[f'{col}_stationary'] = is_stationary
        
        print("\n=== 2. ä¸€éšå·®åˆ†å¹³ç©©æ€§æª¢å®š ===")
        for col in cols:
            diff_series = self.data[col].diff().dropna()
            is_stationary = check_stationarity(diff_series, f'{col}_diff')
            self.results[f'{col}_diff_stationary'] = is_stationary
        
        print("\n=== 3. å…©å…©å…±æ•´åˆæª¢å®š ===")
        from itertools import combinations
        pairs = list(combinations(cols, 2))
        
        coint_matrix = pd.DataFrame(
            index=cols, columns=cols, dtype=float
        )
        
        for col1, col2 in pairs:
            _, pval, _ = coint(self.data[col1], self.data[col2])
            coint_matrix.loc[col1, col2] = pval
            coint_matrix.loc[col2, col1] = pval
            print(f'{col1}-{col2}: p-value = {pval:.4f}')
        
        self.results['coint_matrix'] = coint_matrix
        
        print("\n=== 4. Johansen å¤šè®Šé‡æª¢å®š ===")
        johansen_result = johansen_test(self.data[cols])
        self.results['johansen'] = johansen_result
        
        return self.results
    
    def plot_analysis(self, pair):
        """è¦–è¦ºåŒ–åˆ†æçµæœ"""
        fig, axes = plt.subplots(3, 1, figsize=(12, 10))
        
        # 1. åŸå§‹åºåˆ—
        ax1 = axes[0]
        self.data[pair[0]].plot(ax=ax1, label=pair[0])
        self.data[pair[1]].plot(ax=ax1, label=pair[1], secondary_y=True)
        ax1.set_title('åŸå§‹æ™‚é–“åºåˆ—')
        ax1.legend(loc='upper left')
        
        # 2. æ¨™æº–åŒ–åºåˆ—
        ax2 = axes[1]
        norm_data = (self.data[list(pair)] - self.data[list(pair)].mean()) / self.data[list(pair)].std()
        norm_data.plot(ax=ax2)
        ax2.set_title('æ¨™æº–åŒ–åºåˆ—')
        ax2.legend()
        
        # 3. åƒ¹å·®
        ax3 = axes[2]
        spread, _, _ = CointegrationFeatures().compute_spread(
            self.data[pair[0]], self.data[pair[1]]
        )
        spread.plot(ax=ax3)
        ax3.axhline(y=spread.mean(), color='r', linestyle='--', label='Mean')
        ax3.axhline(y=spread.mean() + 2*spread.std(), color='g', linestyle='--', label='+2Ïƒ')
        ax3.axhline(y=spread.mean() - 2*spread.std(), color='g', linestyle='--', label='-2Ïƒ')
        ax3.set_title('åƒ¹å·® (Spread)')
        ax3.legend()
        
        plt.tight_layout()
        return fig

# ä½¿ç”¨ç¯„ä¾‹
analyzer = CointegrationAnalysis(df)
results = analyzer.full_analysis(['stock1', 'stock2', 'stock3'])
fig = analyzer.plot_analysis(('stock1', 'stock2'))
```

### ğŸ¯ æœ€ä½³å¯¦è¸èˆ‡æ³¨æ„äº‹é …

1. **æ•¸æ“šé è™•ç†**
   - ç¢ºä¿æ™‚é–“åºåˆ—æ²’æœ‰ç¼ºå¤±å€¼
   - å°åƒ¹æ ¼æ•¸æ“šå–å°æ•¸å¯èƒ½æ”¹å–„çµæœ
   - æ³¨æ„æ•¸æ“šé »ç‡çš„ä¸€è‡´æ€§

2. **æª¢å®šé †åº**
   - å…ˆæª¢å®šå¹³ç©©æ€§ï¼ˆADF testï¼‰
   - è‹¥éå¹³ç©©ï¼Œæª¢æŸ¥æ˜¯å¦ I(1) éç¨‹
   - å†é€²è¡Œå…±æ•´åˆæª¢å®š

3. **åƒæ•¸é¸æ“‡**
   - æ»¯å¾Œéšæ•¸ï¼šä½¿ç”¨ AIC/BIC æº–å‰‡
   - çª—å£å¤§å°ï¼šæ ¹æ“šæ•¸æ“šé »ç‡èª¿æ•´ï¼ˆæ—¥é »ï¼š60-252ï¼‰
   - é¡¯è‘—æ€§æ°´å¹³ï¼šé€šå¸¸ä½¿ç”¨ 5%

4. **æ©Ÿå™¨å­¸ç¿’æ‡‰ç”¨**
   - å…±æ•´åˆ p-value ä½œç‚ºç‰¹å¾µ
   - åƒ¹å·®çš„çµ±è¨ˆç‰¹æ€§ä½œç‚ºç‰¹å¾µ
   - çµåˆæŠ€è¡“æŒ‡æ¨™æå‡é æ¸¬

5. **é¢¨éšªç®¡ç†**
   - ç›£æ§å…±æ•´åˆé—œä¿‚çš„ç©©å®šæ€§
   - è¨­ç½®æ­¢æå’Œé¢¨éšªé™åˆ¶
   - å®šæœŸé‡æ–°æ ¡æº–æ¨¡å‹

### ğŸ”— ç›¸é—œè³‡æº

- [Statsmodels æ–‡æª”](https://www.statsmodels.org/)
- [å…±æ•´åˆç†è«–](https://en.wikipedia.org/wiki/Cointegration)
- [VECM æ¨¡å‹](https://www.statsmodels.org/stable/vector_ar.html#vector-error-correction-models-vecm)